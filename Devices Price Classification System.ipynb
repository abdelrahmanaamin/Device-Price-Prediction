{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b79d3d2-ced1-4f33-ba5c-138440fa0fc4",
   "metadata": {},
   "source": [
    "# *Devices Price Classification System*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27217b-e23b-4364-b513-da0587fcdd93",
   "metadata": {},
   "source": [
    "This Notebook is to predict the devices' prices, allowing the sellers to classify the device's prices according to their characteristics. The process will be divided into five parts:\n",
    "* Data Exploration and Preparation\n",
    "* Machine Learning Model\n",
    "* Conclusion\n",
    "* Predicting the price_range of the given test data\n",
    "* Exporting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5b2ff-b247-4a83-ab16-299057d6375d",
   "metadata": {},
   "source": [
    "# **1. Data Exploration and Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e323b5-ca55-4d33-babd-54997b002573",
   "metadata": {},
   "source": [
    "### Installing Dependancies and importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c8451a-6e9c-48e3-a0b3-dabb1759c6b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\abdel\\miniconda3\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\abdel\\miniconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\abdel\\miniconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from seaborn) (2.2.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abdel\\miniconda3\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdel\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# python version 3.11.5\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "93fe0b95-441b-4933-aef3-51b863f257b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca338a-46d5-4421-b7f4-0694f2d24383",
   "metadata": {},
   "source": [
    "### Importing and viewing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9cb33745-747e-4142-b569-b31613f84c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices_df = pd.read_excel(\"train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7f336ef-eb35-429e-b781-3e1468759554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>905.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim    fc  four_g  int_memory  \\\n",
       "0            842     0          2.2         0   1.0     0.0         7.0   \n",
       "1           1021     1          0.5         1   0.0     1.0        53.0   \n",
       "2            563     1          0.5         1   2.0     1.0        41.0   \n",
       "3            615     1          2.5         0   0.0     0.0        10.0   \n",
       "4           1821     1          1.2         0  13.0     1.0        44.0   \n",
       "\n",
       "   m_dep  mobile_wt  n_cores  ...  px_height  px_width     ram  sc_h  sc_w  \\\n",
       "0    0.6      188.0      2.0  ...       20.0     756.0  2549.0   9.0   7.0   \n",
       "1    0.7      136.0      3.0  ...      905.0    1988.0  2631.0  17.0   3.0   \n",
       "2    0.9      145.0      5.0  ...     1263.0    1716.0  2603.0  11.0   2.0   \n",
       "3    0.8      131.0      6.0  ...     1216.0    1786.0  2769.0  16.0   8.0   \n",
       "4    0.6      141.0      2.0  ...     1208.0    1212.0  1411.0   8.0   2.0   \n",
       "\n",
       "   talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0         19        0             0     1            1  \n",
       "1          7        1             1     0            2  \n",
       "2          9        1             1     0            2  \n",
       "3         11        1             0     0            2  \n",
       "4         15        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88642ed2-1d65-44b4-934a-757169019c9a",
   "metadata": {},
   "source": [
    "### Check for any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3db8e20-c072-44b4-8a93-d259b7b2a8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8710b2de-e0a3-45b5-8cbd-d13c3f21a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices_with_nulls_df = devices_df[devices_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90fae8de-ebd2-4bb5-b2bf-04701eda7520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>747.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1356</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1612.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1336</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>194.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>728</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1662</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>143.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1489.0</td>\n",
       "      <td>2822.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>811</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>481.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     battery_power  blue  clock_speed  dual_sim   fc  four_g  int_memory  \\\n",
       "157           1224     0          0.5         0  NaN     NaN         NaN   \n",
       "158           1356     0          2.8         0  NaN     NaN         NaN   \n",
       "217           1336     0          0.9         0  5.0     1.0        17.0   \n",
       "261            728     0          2.7         1  NaN     NaN         NaN   \n",
       "276           1662     0          0.5         0  NaN     NaN         NaN   \n",
       "292           1995     1          1.9         0  6.0     0.0         9.0   \n",
       "293           1517     0          0.5         0  6.0     1.0        48.0   \n",
       "341            811     1          2.4         1  5.0     1.0         2.0   \n",
       "371           1011     0          1.1         0  NaN     NaN         NaN   \n",
       "\n",
       "     m_dep  mobile_wt  n_cores  ...  px_height  px_width     ram  sc_h  sc_w  \\\n",
       "157    NaN        NaN      NaN  ...      747.0     826.0   506.0  10.0   0.0   \n",
       "158    NaN        NaN      NaN  ...     1612.0    1983.0  3702.0  17.0   0.0   \n",
       "217    NaN      194.0      5.0  ...       55.0     583.0  1869.0  13.0   1.0   \n",
       "261    NaN        NaN      NaN  ...        NaN       NaN     NaN   5.0   1.0   \n",
       "276    0.8      126.0      4.0  ...       32.0    1509.0  3760.0   9.0   5.0   \n",
       "292    0.8      139.0      6.0  ...        NaN    1963.0  1203.0  14.0  12.0   \n",
       "293    0.6      143.0      5.0  ...        NaN    1489.0  2822.0  15.0   5.0   \n",
       "341    0.3      106.0      6.0  ...        NaN       NaN     NaN   NaN   NaN   \n",
       "371    NaN        NaN      NaN  ...      481.0     749.0  2261.0   7.0   6.0   \n",
       "\n",
       "     talk_time  three_g  touch_screen  wifi  price_range  \n",
       "157         11        1             1     1            0  \n",
       "158         19        0             0     0            3  \n",
       "217         16        1             1     1            1  \n",
       "261         12        1             1     1            1  \n",
       "276         13        1             1     1            3  \n",
       "292         18        1             1     1            2  \n",
       "293         11        1             1     1            3  \n",
       "341          2        1             0     1            1  \n",
       "371         16        1             1     1            1  \n",
       "\n",
       "[9 rows x 21 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_with_nulls_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60758557-1303-4bec-9ea5-97a5ebf76186",
   "metadata": {},
   "source": [
    "### Since there are only 9 rows with nulls in them we could discard them without affecting the whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77231d1d-4877-4858-bd2b-fa5d8b54333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices_df = devices_df[devices_df.notna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc2c2daf-4422-4f99-98b4-c9ed0cfa5bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>905.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>915.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>2032.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>868.0</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>3057.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>336.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>483.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>3919.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1991 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim    fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1.0     0.0         7.0   \n",
       "1              1021     1          0.5         1   0.0     1.0        53.0   \n",
       "2               563     1          0.5         1   2.0     1.0        41.0   \n",
       "3               615     1          2.5         0   0.0     0.0        10.0   \n",
       "4              1821     1          1.2         0  13.0     1.0        44.0   \n",
       "...             ...   ...          ...       ...   ...     ...         ...   \n",
       "1995            794     1          0.5         1   0.0     1.0         2.0   \n",
       "1996           1965     1          2.6         1   0.0     0.0        39.0   \n",
       "1997           1911     0          0.9         1   1.0     1.0        36.0   \n",
       "1998           1512     0          0.9         0   4.0     1.0        46.0   \n",
       "1999            510     1          2.0         1   5.0     1.0        45.0   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  ...  px_height  px_width     ram  sc_h  sc_w  \\\n",
       "0       0.6      188.0      2.0  ...       20.0     756.0  2549.0   9.0   7.0   \n",
       "1       0.7      136.0      3.0  ...      905.0    1988.0  2631.0  17.0   3.0   \n",
       "2       0.9      145.0      5.0  ...     1263.0    1716.0  2603.0  11.0   2.0   \n",
       "3       0.8      131.0      6.0  ...     1216.0    1786.0  2769.0  16.0   8.0   \n",
       "4       0.6      141.0      2.0  ...     1208.0    1212.0  1411.0   8.0   2.0   \n",
       "...     ...        ...      ...  ...        ...       ...     ...   ...   ...   \n",
       "1995    0.8      106.0      6.0  ...     1222.0    1890.0   668.0  13.0   4.0   \n",
       "1996    0.2      187.0      4.0  ...      915.0    1965.0  2032.0  11.0  10.0   \n",
       "1997    0.7      108.0      8.0  ...      868.0    1632.0  3057.0   9.0   1.0   \n",
       "1998    0.1      145.0      5.0  ...      336.0     670.0   869.0  18.0  10.0   \n",
       "1999    0.9      168.0      6.0  ...      483.0     754.0  3919.0  19.0   4.0   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0            19        0             0     1            1  \n",
       "1             7        1             1     0            2  \n",
       "2             9        1             1     0            2  \n",
       "3            11        1             0     0            2  \n",
       "4            15        1             1     0            1  \n",
       "...         ...      ...           ...   ...          ...  \n",
       "1995         19        1             1     0            0  \n",
       "1996         16        1             1     1            2  \n",
       "1997          5        1             1     0            3  \n",
       "1998         19        1             1     1            0  \n",
       "1999          2        1             1     1            3  \n",
       "\n",
       "[1991 rows x 21 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b90ff-f32f-4460-8fcd-7dbb711cccfc",
   "metadata": {},
   "source": [
    "### Check for the columns with the string values and convert them to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cdb8c9e7-ec9a-4685-91c5-a317ba71adf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "battery_power      int64\n",
       "blue               int64\n",
       "clock_speed      float64\n",
       "dual_sim           int64\n",
       "fc               float64\n",
       "four_g           float64\n",
       "int_memory       float64\n",
       "m_dep            float64\n",
       "mobile_wt        float64\n",
       "n_cores          float64\n",
       "pc               float64\n",
       "px_height        float64\n",
       "px_width         float64\n",
       "ram              float64\n",
       "sc_h             float64\n",
       "sc_w             float64\n",
       "talk_time          int64\n",
       "three_g            int64\n",
       "touch_screen       int64\n",
       "wifi               int64\n",
       "price_range        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e2bff5c-e98c-498f-a258-2da6c5da7336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "string_cols = list(devices_df.select_dtypes(['object']).columns)\n",
    "print(string_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f1b0faf-1a32-485b-b903-a3e9cafa0c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_range\n",
       "2    499\n",
       "0    499\n",
       "3    497\n",
       "1    496\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_df['price_range'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11213479-7071-480c-b5e6-ba8d5b1e5a33",
   "metadata": {},
   "source": [
    "### Dividing the devices according to 'price_range' and get the difference in means of all other features.\n",
    "#### NOTE: Although nothing will be done with the features with most and least mean difference this will be an indicator to which factors affect price range and which have zero to no effect and will help in understanding the data before applying any operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8bab65f-8b0c-4152-8d56-d8e34e087f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_range_0_insights_df = devices_df[devices_df['price_range']==0]\n",
    "price_range_1_insights_df = devices_df[devices_df['price_range']==1]\n",
    "price_range_2_insights_df = devices_df[devices_df['price_range']==2]\n",
    "price_range_3_insights_df = devices_df[devices_df['price_range']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6e9d5cd6-58bf-48b9-ad15-d1c592201eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Price Range 0 battery_power  Price Range 1 battery_power  \\\n",
      "mean                  1116.687375                  1230.943548   \n",
      "std                    411.185487                   439.265701   \n",
      "min                    503.000000                   501.000000   \n",
      "25%                    770.000000                   846.750000   \n",
      "50%                   1066.000000                  1209.000000   \n",
      "75%                   1431.500000                  1600.500000   \n",
      "max                   1994.000000                  1996.000000   \n",
      "\n",
      "      Price Range 2 battery_power  Price Range 3 battery_power  \n",
      "mean                  1226.783567                  1379.189135  \n",
      "std                    452.011161                   416.005084  \n",
      "min                    501.000000                   503.000000  \n",
      "25%                    815.000000                  1034.000000  \n",
      "50%                   1219.000000                  1448.000000  \n",
      "75%                   1633.500000                  1735.000000  \n",
      "max                   1998.000000                  1994.000000  \n",
      "      Price Range 0 blue  Price Range 1 blue  Price Range 2 blue  \\\n",
      "mean            0.486974            0.491935            0.484970   \n",
      "std             0.500332            0.500440            0.500276   \n",
      "min             0.000000            0.000000            0.000000   \n",
      "25%             0.000000            0.000000            0.000000   \n",
      "50%             0.000000            0.000000            0.000000   \n",
      "75%             1.000000            1.000000            1.000000   \n",
      "max             1.000000            1.000000            1.000000   \n",
      "\n",
      "      Price Range 3 blue  \n",
      "mean            0.521127  \n",
      "std             0.500057  \n",
      "min             0.000000  \n",
      "25%             0.000000  \n",
      "50%             1.000000  \n",
      "75%             1.000000  \n",
      "max             1.000000  \n",
      "      Price Range 0 clock_speed  Price Range 1 clock_speed  \\\n",
      "mean                   1.552305                    1.48629   \n",
      "std                    0.848487                    0.81430   \n",
      "min                    0.500000                    0.50000   \n",
      "25%                    0.600000                    0.60000   \n",
      "50%                    1.600000                    1.50000   \n",
      "75%                    2.300000                    2.20000   \n",
      "max                    3.000000                    3.00000   \n",
      "\n",
      "      Price Range 2 clock_speed  Price Range 3 clock_speed  \n",
      "mean                   1.529058                   1.521932  \n",
      "std                    0.805040                   0.794146  \n",
      "min                    0.500000                   0.500000  \n",
      "25%                    0.700000                   0.700000  \n",
      "50%                    1.500000                   1.500000  \n",
      "75%                    2.200000                   2.200000  \n",
      "max                    3.000000                   3.000000  \n",
      "      Price Range 0 dual_sim  Price Range 1 dual_sim  Price Range 2 dual_sim  \\\n",
      "mean                0.501002                0.510081                0.498998   \n",
      "std                 0.500501                0.500403                0.500501   \n",
      "min                 0.000000                0.000000                0.000000   \n",
      "25%                 0.000000                0.000000                0.000000   \n",
      "50%                 1.000000                1.000000                0.000000   \n",
      "75%                 1.000000                1.000000                1.000000   \n",
      "max                 1.000000                1.000000                1.000000   \n",
      "\n",
      "      Price Range 3 dual_sim  \n",
      "mean                0.533199  \n",
      "std                 0.499399  \n",
      "min                 0.000000  \n",
      "25%                 0.000000  \n",
      "50%                 1.000000  \n",
      "75%                 1.000000  \n",
      "max                 1.000000  \n",
      "      Price Range 0 fc  Price Range 1 fc  Price Range 2 fc  Price Range 3 fc\n",
      "mean          4.060120          4.346774          4.494990          4.329980\n",
      "std           4.153722          4.513136          4.351231          4.336149\n",
      "min           0.000000          0.000000          0.000000          0.000000\n",
      "25%           1.000000          1.000000          1.000000          1.000000\n",
      "50%           3.000000          3.000000          3.000000          3.000000\n",
      "75%           6.000000          7.000000          7.000000          7.000000\n",
      "max          19.000000         18.000000         18.000000         18.000000\n",
      "      Price Range 0 four_g  Price Range 1 four_g  Price Range 2 four_g  \\\n",
      "mean              0.517034              0.522177              0.494990   \n",
      "std               0.500211              0.500012              0.500477   \n",
      "min               0.000000              0.000000              0.000000   \n",
      "25%               0.000000              0.000000              0.000000   \n",
      "50%               1.000000              1.000000              0.000000   \n",
      "75%               1.000000              1.000000              1.000000   \n",
      "max               1.000000              1.000000              1.000000   \n",
      "\n",
      "      Price Range 3 four_g  \n",
      "mean              0.549296  \n",
      "std               0.498065  \n",
      "min               0.000000  \n",
      "25%               0.000000  \n",
      "50%               1.000000  \n",
      "75%               1.000000  \n",
      "max               1.000000  \n",
      "      Price Range 0 int_memory  Price Range 1 int_memory  \\\n",
      "mean                 31.224449                 32.213710   \n",
      "std                  18.083966                 18.005799   \n",
      "min                   2.000000                  2.000000   \n",
      "25%                  15.000000                 16.000000   \n",
      "50%                  30.000000                 32.000000   \n",
      "75%                  47.000000                 47.000000   \n",
      "max                  64.000000                 64.000000   \n",
      "\n",
      "      Price Range 2 int_memory  Price Range 3 int_memory  \n",
      "mean                 30.963928                 33.903421  \n",
      "std                  18.434261                 17.930948  \n",
      "min                   2.000000                  2.000000  \n",
      "25%                  15.000000                 18.000000  \n",
      "50%                  30.000000                 34.000000  \n",
      "75%                  48.000000                 49.000000  \n",
      "max                  64.000000                 64.000000  \n",
      "      Price Range 0 m_dep  Price Range 1 m_dep  Price Range 2 m_dep  \\\n",
      "mean             0.490381             0.526411             0.490180   \n",
      "std              0.288445             0.286758             0.286167   \n",
      "min              0.100000             0.100000             0.100000   \n",
      "25%              0.200000             0.300000             0.200000   \n",
      "50%              0.500000             0.500000             0.500000   \n",
      "75%              0.700000             0.800000             0.700000   \n",
      "max              1.000000             1.000000             1.000000   \n",
      "\n",
      "      Price Range 3 m_dep  \n",
      "mean             0.501207  \n",
      "std              0.292443  \n",
      "min              0.100000  \n",
      "25%              0.200000  \n",
      "50%              0.500000  \n",
      "75%              0.800000  \n",
      "max              1.000000  \n",
      "      Price Range 0 mobile_wt  Price Range 1 mobile_wt  \\\n",
      "mean               140.615230               140.596774   \n",
      "std                 36.387311                35.627630   \n",
      "min                 80.000000                80.000000   \n",
      "25%                108.500000               109.000000   \n",
      "50%                142.000000               141.000000   \n",
      "75%                173.000000               170.000000   \n",
      "max                200.000000               200.000000   \n",
      "\n",
      "      Price Range 2 mobile_wt  Price Range 3 mobile_wt  \n",
      "mean               143.623246               136.203219  \n",
      "std                 34.354143                34.903163  \n",
      "min                 80.000000                80.000000  \n",
      "25%                114.000000               104.000000  \n",
      "50%                145.000000               134.000000  \n",
      "75%                172.000000               165.000000  \n",
      "max                200.000000               200.000000  \n",
      "      Price Range 0 n_cores  Price Range 1 n_cores  Price Range 2 n_cores  \\\n",
      "mean               4.597194               4.288306               4.679359   \n",
      "std                2.269952               2.316289               2.264045   \n",
      "min                1.000000               1.000000               1.000000   \n",
      "25%                3.000000               2.000000               3.000000   \n",
      "50%                5.000000               4.000000               5.000000   \n",
      "75%                7.000000               6.000000               7.000000   \n",
      "max                8.000000               8.000000               8.000000   \n",
      "\n",
      "      Price Range 3 n_cores  \n",
      "mean               4.498994  \n",
      "std                2.302807  \n",
      "min                1.000000  \n",
      "25%                2.000000  \n",
      "50%                5.000000  \n",
      "75%                7.000000  \n",
      "max                8.000000  \n",
      "      Price Range 0 pc  Price Range 1 pc  Price Range 2 pc  Price Range 3 pc\n",
      "mean          9.557114          9.921371         10.002004         10.156942\n",
      "std           6.090206          6.123961          5.948068          6.083054\n",
      "min           0.000000          0.000000          0.000000          0.000000\n",
      "25%           4.000000          4.000000          5.000000          5.000000\n",
      "50%           9.000000         10.000000         10.000000         10.000000\n",
      "75%          14.500000         15.000000         15.000000         16.000000\n",
      "max          20.000000         20.000000         20.000000         20.000000\n",
      "      Price Range 0 px_height  Price Range 1 px_height  \\\n",
      "mean               535.985972               669.457661   \n",
      "std                373.078727               441.890080   \n",
      "min                  1.000000                 0.000000   \n",
      "25%                229.000000               327.250000   \n",
      "50%                465.000000               607.500000   \n",
      "75%                777.000000               945.250000   \n",
      "max               1878.000000              1914.000000   \n",
      "\n",
      "      Price Range 2 px_height  Price Range 3 px_height  \n",
      "mean               629.883768               744.422535  \n",
      "std                442.990688               482.548592  \n",
      "min                 10.000000                 0.000000  \n",
      "25%                252.000000               342.000000  \n",
      "50%                535.000000               674.000000  \n",
      "75%                936.000000              1109.000000  \n",
      "max               1960.000000              1949.000000  \n",
      "      Price Range 0 px_width  Price Range 1 px_width  Price Range 2 px_width  \\\n",
      "mean             1150.919840             1253.354839             1232.585170   \n",
      "std               413.160273              433.430086              426.936117   \n",
      "min               500.000000              500.000000              508.000000   \n",
      "25%               804.500000              880.500000              861.000000   \n",
      "50%              1133.000000             1223.000000             1220.000000   \n",
      "75%              1453.500000             1630.000000             1613.000000   \n",
      "max              1989.000000             1998.000000             1997.000000   \n",
      "\n",
      "      Price Range 3 px_width  \n",
      "mean             1368.084507  \n",
      "std               427.143410  \n",
      "min               501.000000  \n",
      "25%              1040.000000  \n",
      "50%              1409.000000  \n",
      "75%              1746.000000  \n",
      "max              1995.000000  \n",
      "      Price Range 0 ram  Price Range 1 ram  Price Range 2 ram  \\\n",
      "mean         785.873747        1676.340726        2585.581162   \n",
      "std          362.903217         466.226488         492.838491   \n",
      "min          256.000000         387.000000        1185.000000   \n",
      "25%          488.500000        1353.500000        2296.000000   \n",
      "50%          720.000000        1675.000000        2577.000000   \n",
      "75%         1037.000000        2027.500000        2927.000000   \n",
      "max         1974.000000        2811.000000        3916.000000   \n",
      "\n",
      "      Price Range 3 ram  \n",
      "mean        3449.360161  \n",
      "std          392.787722  \n",
      "min         2259.000000  \n",
      "25%         3208.000000  \n",
      "50%         3508.000000  \n",
      "75%         3767.000000  \n",
      "max         3998.000000  \n",
      "      Price Range 0 sc_h  Price Range 1 sc_h  Price Range 2 sc_h  \\\n",
      "mean           12.328657           12.223790           12.006012   \n",
      "std             4.209880            4.216887            4.237664   \n",
      "min             5.000000            5.000000            5.000000   \n",
      "25%             9.000000            8.000000            8.000000   \n",
      "50%            12.000000           12.000000           12.000000   \n",
      "75%            16.000000           16.000000           16.000000   \n",
      "max            19.000000           19.000000           19.000000   \n",
      "\n",
      "      Price Range 3 sc_h  \n",
      "mean           12.674044  \n",
      "std             4.172489  \n",
      "min             5.000000  \n",
      "25%             9.000000  \n",
      "50%            13.000000  \n",
      "75%            16.000000  \n",
      "max            19.000000  \n",
      "      Price Range 0 sc_w  Price Range 1 sc_w  Price Range 2 sc_w  \\\n",
      "mean            5.693387            5.558468            5.701403   \n",
      "std             4.170582            4.245569            4.260708   \n",
      "min             0.000000            0.000000            0.000000   \n",
      "25%             2.000000            2.000000            2.000000   \n",
      "50%             5.000000            5.000000            5.000000   \n",
      "75%             8.500000            8.000000            8.000000   \n",
      "max            18.000000           18.000000           17.000000   \n",
      "\n",
      "      Price Range 3 sc_w  \n",
      "mean            6.144869  \n",
      "std             4.722452  \n",
      "min             0.000000  \n",
      "25%             2.000000  \n",
      "50%             5.000000  \n",
      "75%            10.000000  \n",
      "max            18.000000  \n",
      "      Price Range 0 talk_time  Price Range 1 talk_time  \\\n",
      "mean                10.611222                11.360887   \n",
      "std                  5.402397                 5.569470   \n",
      "min                  2.000000                 2.000000   \n",
      "25%                  6.000000                 7.000000   \n",
      "50%                 10.000000                12.000000   \n",
      "75%                 15.000000                16.000000   \n",
      "max                 20.000000                20.000000   \n",
      "\n",
      "      Price Range 2 talk_time  Price Range 3 talk_time  \n",
      "mean                10.957916                11.078471  \n",
      "std                  5.429378                 5.447317  \n",
      "min                  2.000000                 2.000000  \n",
      "25%                  6.000000                 7.000000  \n",
      "50%                 11.000000                11.000000  \n",
      "75%                 16.000000                16.000000  \n",
      "max                 20.000000                20.000000  \n",
      "      Price Range 0 three_g  Price Range 1 three_g  Price Range 2 three_g  \\\n",
      "mean               0.745491               0.754032               0.773547   \n",
      "std                0.436022               0.431094               0.418956   \n",
      "min                0.000000               0.000000               0.000000   \n",
      "25%                0.000000               1.000000               1.000000   \n",
      "50%                1.000000               1.000000               1.000000   \n",
      "75%                1.000000               1.000000               1.000000   \n",
      "max                1.000000               1.000000               1.000000   \n",
      "\n",
      "      Price Range 3 three_g  \n",
      "mean               0.770624  \n",
      "std                0.420855  \n",
      "min                0.000000  \n",
      "25%                1.000000  \n",
      "50%                1.000000  \n",
      "75%                1.000000  \n",
      "max                1.000000  \n",
      "      Price Range 0 touch_screen  Price Range 1 touch_screen  \\\n",
      "mean                    0.523046                    0.520161   \n",
      "std                     0.499970                    0.500098   \n",
      "min                     0.000000                    0.000000   \n",
      "25%                     0.000000                    0.000000   \n",
      "50%                     1.000000                    1.000000   \n",
      "75%                     1.000000                    1.000000   \n",
      "max                     1.000000                    1.000000   \n",
      "\n",
      "      Price Range 2 touch_screen  Price Range 3 touch_screen  \n",
      "mean                    0.468938                    0.494970  \n",
      "std                     0.499535                    0.500478  \n",
      "min                     0.000000                    0.000000  \n",
      "25%                     0.000000                    0.000000  \n",
      "50%                     0.000000                    0.000000  \n",
      "75%                     1.000000                    1.000000  \n",
      "max                     1.000000                    1.000000  \n",
      "      Price Range 0 wifi  Price Range 1 wifi  Price Range 2 wifi  \\\n",
      "mean            0.494990            0.500000            0.503006   \n",
      "std             0.500477            0.500505            0.500493   \n",
      "min             0.000000            0.000000            0.000000   \n",
      "25%             0.000000            0.000000            0.000000   \n",
      "50%             0.000000            0.500000            1.000000   \n",
      "75%             1.000000            1.000000            1.000000   \n",
      "max             1.000000            1.000000            1.000000   \n",
      "\n",
      "      Price Range 3 wifi  \n",
      "mean            0.523139  \n",
      "std             0.499968  \n",
      "min             0.000000  \n",
      "25%             0.000000  \n",
      "50%             1.000000  \n",
      "75%             1.000000  \n",
      "max             1.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
      "C:\\Users\\abdel\\AppData\\Local\\Temp\\ipykernel_2324\\1802098440.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n"
     ]
    }
   ],
   "source": [
    "ignore_cols = ['price_range']\n",
    "diff_in_mean = {}\n",
    "for col in devices_df:\n",
    "    if col not in ignore_cols:\n",
    "        description_df = pd.concat([price_range_0_insights_df[col].describe(), price_range_1_insights_df[col].describe()\n",
    "                                    , price_range_2_insights_df[col].describe(), price_range_3_insights_df[col].describe()],\n",
    "                     keys=['Price Range 0 '+col, 'Price Range 1 '+col, 'Price Range 2 '+col, 'Price Range 3 '+col],\n",
    "                     axis=1).drop('count')\n",
    "        diff_in_mean[col] = (abs(description_df.iloc[0][0] - description_df.iloc[0][1]) + abs(description_df.iloc[0][1] - description_df.iloc[0][2])\n",
    "                            + abs(description_df.iloc[0][2] - description_df.iloc[0][3]) + abs(description_df.iloc[0][3] - description_df.iloc[0][0]))/4\n",
    "        print(description_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ddb63b-f4af-4ff0-985a-5ac8776fa2bd",
   "metadata": {},
   "source": [
    "### It is obvious that ram will be the factor that will affect price_range the most. Followed by battery power, px_height and px_width. The latter 3 with much less effect than the ram.\n",
    "### Also, it appears that three_g,wifi and blue factors will have negligible effect to the prediction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1cbe5050-e2b6-42ad-85ca-cb74794904ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'three_g': 0.014028056112224463,\n",
       " 'wifi': 0.014074426519034039,\n",
       " 'blue': 0.020559178329398464,\n",
       " 'dual_sim': 0.021639920166158316,\n",
       " 'm_dep': 0.02352870576942817,\n",
       " 'touch_screen': 0.027054108216432837,\n",
       " 'four_g': 0.029724572953266887,\n",
       " 'clock_speed': 0.03657040666651645,\n",
       " 'fc': 0.217434869739479,\n",
       " 'n_cores': 0.24462634540841277,\n",
       " 'sc_w': 0.2932007366781333,\n",
       " 'pc': 0.29991371072124107,\n",
       " 'sc_h': 0.33401612077273235,\n",
       " 'talk_time': 0.4351098225853933,\n",
       " 'int_memory': 1.9643767235255876,\n",
       " 'mobile_wt': 3.7192417222320273,\n",
       " 'px_width': 118.96716786594538,\n",
       " 'px_height': 124.00522851131615,\n",
       " 'battery_power': 133.3308706560913,\n",
       " 'ram': 1331.7432067354025}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_in_mean = dict(sorted(diff_in_mean.items(), key=lambda item: item[1]))\n",
    "diff_in_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a5a39-25b8-49a3-8953-05900991d13c",
   "metadata": {},
   "source": [
    "### Displaying the correlation matrix for observations and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1bcf228f-c28b-45fb-a762-6d1bbd05cf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 5500x5500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = devices_df.corr()\n",
    "f, ax = plt.subplots(figsize=(55, 55))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a1271-69a6-4ff1-8d36-7322978d1313",
   "metadata": {},
   "source": [
    "### Function for removing highly correlated features. (Threshold: 95%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2f9ccded-3af3-44c4-9a15-21408f76e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_collinear_features(df, threshold):\n",
    "    corr_matrix = df.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                drop_cols.append(col.values[0])\n",
    "    drops = set(drop_cols)\n",
    "    print('Removed Columns {}'.format(drops))\n",
    "    df = df.drop(columns=drops)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfa280e-0cd2-4d0c-a6ef-3a711a3aca77",
   "metadata": {},
   "source": [
    "### No columns are highly correlated to each others, so the removed set is Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8558ebab-846b-48f4-a589-629b70934358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Columns set()\n"
     ]
    }
   ],
   "source": [
    "devices_df = remove_collinear_features(devices_df,0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfabd1-81a9-4dd3-987d-f16993502f17",
   "metadata": {},
   "source": [
    "### Normalising all values to be between 0 and 1 to avoid bias towards features with high numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0267d39a-fe36-46fa-a448-0f1097bfa29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_devices_df = devices_df.apply(lambda x: x/x.max(), axis=0)\n",
    "normalized_devices_df['price_range'] = devices_df['price_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "909cf057-dcd0-4d19-967f-4f8a6882222f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.421421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.637569</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461735</td>\n",
       "      <td>0.994995</td>\n",
       "      <td>0.658079</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.281782</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644388</td>\n",
       "      <td>0.858859</td>\n",
       "      <td>0.651076</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620408</td>\n",
       "      <td>0.893894</td>\n",
       "      <td>0.692596</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.911411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616327</td>\n",
       "      <td>0.606607</td>\n",
       "      <td>0.352926</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.397397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623469</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.167084</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.983483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466837</td>\n",
       "      <td>0.983483</td>\n",
       "      <td>0.508254</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.956456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.540</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.816817</td>\n",
       "      <td>0.764632</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.335335</td>\n",
       "      <td>0.217359</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.255255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246429</td>\n",
       "      <td>0.377377</td>\n",
       "      <td>0.980240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1991 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim        fc  four_g  \\\n",
       "0          0.421421   0.0     0.733333       0.0  0.052632     0.0   \n",
       "1          0.511011   1.0     0.166667       1.0  0.000000     1.0   \n",
       "2          0.281782   1.0     0.166667       1.0  0.105263     1.0   \n",
       "3          0.307808   1.0     0.833333       0.0  0.000000     0.0   \n",
       "4          0.911411   1.0     0.400000       0.0  0.684211     1.0   \n",
       "...             ...   ...          ...       ...       ...     ...   \n",
       "1995       0.397397   1.0     0.166667       1.0  0.000000     1.0   \n",
       "1996       0.983483   1.0     0.866667       1.0  0.000000     0.0   \n",
       "1997       0.956456   0.0     0.300000       1.0  0.052632     1.0   \n",
       "1998       0.756757   0.0     0.300000       0.0  0.210526     1.0   \n",
       "1999       0.255255   1.0     0.666667       1.0  0.263158     1.0   \n",
       "\n",
       "      int_memory  m_dep  mobile_wt  n_cores  ...  px_height  px_width  \\\n",
       "0       0.109375    0.6      0.940    0.250  ...   0.010204  0.378378   \n",
       "1       0.828125    0.7      0.680    0.375  ...   0.461735  0.994995   \n",
       "2       0.640625    0.9      0.725    0.625  ...   0.644388  0.858859   \n",
       "3       0.156250    0.8      0.655    0.750  ...   0.620408  0.893894   \n",
       "4       0.687500    0.6      0.705    0.250  ...   0.616327  0.606607   \n",
       "...          ...    ...        ...      ...  ...        ...       ...   \n",
       "1995    0.031250    0.8      0.530    0.750  ...   0.623469  0.945946   \n",
       "1996    0.609375    0.2      0.935    0.500  ...   0.466837  0.983483   \n",
       "1997    0.562500    0.7      0.540    1.000  ...   0.442857  0.816817   \n",
       "1998    0.718750    0.1      0.725    0.625  ...   0.171429  0.335335   \n",
       "1999    0.703125    0.9      0.840    0.750  ...   0.246429  0.377377   \n",
       "\n",
       "           ram      sc_h      sc_w  talk_time  three_g  touch_screen  wifi  \\\n",
       "0     0.637569  0.473684  0.388889       0.95      0.0           0.0   1.0   \n",
       "1     0.658079  0.894737  0.166667       0.35      1.0           1.0   0.0   \n",
       "2     0.651076  0.578947  0.111111       0.45      1.0           1.0   0.0   \n",
       "3     0.692596  0.842105  0.444444       0.55      1.0           0.0   0.0   \n",
       "4     0.352926  0.421053  0.111111       0.75      1.0           1.0   0.0   \n",
       "...        ...       ...       ...        ...      ...           ...   ...   \n",
       "1995  0.167084  0.684211  0.222222       0.95      1.0           1.0   0.0   \n",
       "1996  0.508254  0.578947  0.555556       0.80      1.0           1.0   1.0   \n",
       "1997  0.764632  0.473684  0.055556       0.25      1.0           1.0   0.0   \n",
       "1998  0.217359  0.947368  0.555556       0.95      1.0           1.0   1.0   \n",
       "1999  0.980240  1.000000  0.222222       0.10      1.0           1.0   1.0   \n",
       "\n",
       "      price_range  \n",
       "0               1  \n",
       "1               2  \n",
       "2               2  \n",
       "3               2  \n",
       "4               1  \n",
       "...           ...  \n",
       "1995            0  \n",
       "1996            2  \n",
       "1997            3  \n",
       "1998            0  \n",
       "1999            3  \n",
       "\n",
       "[1991 rows x 21 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_devices_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835f0f5-afed-43a0-b395-49ffdd23158e",
   "metadata": {},
   "source": [
    "### Splitting the data to train (80%) and test (20%), as the test data provided does not have price_range labels we will split the train data provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c29ace8-8add-468c-9570-357e0678d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(normalized_devices_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ca250-9cb9-4a9d-84b2-f6c36ed37d3a",
   "metadata": {},
   "source": [
    "### Confirming that the all the data sets have the same Price Range ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f471f9f-9a83-4ab1-b95d-6ce5619dc951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Range 0 in Original Data:  0.25062782521346055\n",
      "Price Range 0 in Training Data:  0.25\n",
      "Price Range 0 in Testing Data:  0.2531328320802005\n"
     ]
    }
   ],
   "source": [
    "print(\"Price Range 0 in Original Data: \",(normalized_devices_df['price_range'].value_counts()[0]/len(normalized_devices_df.index)))\n",
    "print(\"Price Range 0 in Training Data: \",(train['price_range'].value_counts()[0]/len(train.index)))\n",
    "print(\"Price Range 0 in Testing Data: \",(test['price_range'].value_counts()[0]/len(test.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd987472-3997-48d0-bf8f-ed570a4b9970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Range 1 in Original Data:  0.2491210447011552\n",
      "Price Range 1 in Training Data:  0.24748743718592964\n",
      "Price Range 1 in Testing Data:  0.2556390977443609\n"
     ]
    }
   ],
   "source": [
    "print(\"Price Range 1 in Original Data: \",(normalized_devices_df['price_range'].value_counts()[1]/len(normalized_devices_df.index)))\n",
    "print(\"Price Range 1 in Training Data: \",(train['price_range'].value_counts()[1]/len(train.index)))\n",
    "print(\"Price Range 1 in Testing Data: \",(test['price_range'].value_counts()[1]/len(test.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8dd9898e-3d84-46a8-84f6-9665c86a07a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Range 2 in Original Data:  0.25062782521346055\n",
      "Price Range 2 in Training Data:  0.2518844221105528\n",
      "Price Range 2 in Testing Data:  0.24561403508771928\n"
     ]
    }
   ],
   "source": [
    "print(\"Price Range 2 in Original Data: \",(normalized_devices_df['price_range'].value_counts()[2]/len(normalized_devices_df.index)))\n",
    "print(\"Price Range 2 in Training Data: \",(train['price_range'].value_counts()[2]/len(train.index)))\n",
    "print(\"Price Range 2 in Testing Data: \",(test['price_range'].value_counts()[2]/len(test.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "42f5f640-6e5b-42e2-accc-508556a463b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Range 3 in Original Data:  0.24962330487192366\n",
      "Price Range 3 in Training Data:  0.2506281407035176\n",
      "Price Range 3 in Testing Data:  0.24561403508771928\n"
     ]
    }
   ],
   "source": [
    "print(\"Price Range 3 in Original Data: \",(normalized_devices_df['price_range'].value_counts()[3]/len(normalized_devices_df.index)))\n",
    "print(\"Price Range 3 in Training Data: \",(train['price_range'].value_counts()[3]/len(train.index)))\n",
    "print(\"Price Range 3 in Testing Data: \",(test['price_range'].value_counts()[3]/len(test.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43578e0-b283-4084-9579-8b5d656af567",
   "metadata": {},
   "source": [
    "### Getting the labels for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "25cce90e-1025-4f90-b5e9-4a955c0cf603",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train['price_range']\n",
    "train_data = train.drop('price_range', axis=1)\n",
    "test_labels = test['price_range']\n",
    "test_data = test.drop('price_range', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ebc2f8-19ca-41f7-a8a5-70a408a2ddd9",
   "metadata": {},
   "source": [
    "# **2. Machine Learning Model**\n",
    "*This part is for choosing the most suitable model for predicting the attrition of the employees. This process involved four algorithms each of which was tested using their default parameters and evaluated for accuracy then hyperparameter tuning was applied to each one for trying to find the best performing altgorithm out of the following:*\n",
    "* SVM\n",
    "* Naive Bayes\n",
    "* Logistic Regression\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e80b47-5d87-4c91-940d-0d6f1ed129da",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f7f3b820-d96f-4cd8-b6af-c169959548c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "be518393-1108-4f7b-902a-3e3de9672a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370927318295739"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_predictions = svm_classifier.predict(test_data)\n",
    "accuracy_score(test_labels,svm_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01565e9d-8622-4828-8957-efc835401d7d",
   "metadata": {},
   "source": [
    "## SVM Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a9df3eda-4320-44f3-b10a-11c57e3f83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "24211a93-936f-4577-b73c-120b4ed68275",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_htuning = GridSearchCV(SVC(), svm_param_grid, verbose = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5d02a418-d49a-48e5-9e86-8cf2d49b3cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.849 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.887 total time=   0.0s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.266 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.266 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.252 total time=   0.1s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.255 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.545 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.505 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.431 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.469 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.481 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.549 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.561 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.535 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.547 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.538 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.348 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.364 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.289 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.283 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.314 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.915 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.943 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.646 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.671 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.682 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.251 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.254 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.252 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.252 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.252 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.915 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.943 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.806 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.853 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.865 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.849 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.865 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.796 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.915 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.943 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.596 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.629 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.619 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.480 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.489 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.415 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.396 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.403 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.915 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.943 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.915 total time=   0.0s\n",
      "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.943 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.959 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ........C=10, gamma=1, kernel=poly;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.715 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.682 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.720 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.216 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.194 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.211 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.233 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.230 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.959 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.855 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.890 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.896 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.655 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.682 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.651 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.959 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.899 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.959 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.592 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.602 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.626 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.610 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.638 total time=   0.0s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.480 total time=   0.0s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.489 total time=   0.0s\n",
      "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.415 total time=   0.0s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.396 total time=   0.0s\n",
      "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.403 total time=   0.0s\n",
      "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.959 total time=   0.0s\n",
      "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.965 total time=   0.0s\n",
      "[CV 1/5] END .......C=100, gamma=1, kernel=poly;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END .......C=100, gamma=1, kernel=poly;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END .......C=100, gamma=1, kernel=poly;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END .......C=100, gamma=1, kernel=poly;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END .......C=100, gamma=1, kernel=poly;, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.715 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.682 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.720 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.194 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.245 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.173 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.214 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.198 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.965 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.849 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.887 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.890 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.877 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.899 total time=   0.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.589 total time=   0.0s\n",
      "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.596 total time=   0.0s\n",
      "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.657 total time=   0.0s\n",
      "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.638 total time=   0.0s\n",
      "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.642 total time=   0.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.965 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.545 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.505 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.431 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.469 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.481 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.915 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.934 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.940 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.921 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.965 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.915 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.925 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.909 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=linear;, score=0.962 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=linear;, score=0.965 total time=   0.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.592 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.602 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.629 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.610 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.638 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.480 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.489 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.415 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.396 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.403 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=1, kernel=linear;, score=0.975 total time=   0.1s\n",
      "[CV 2/5] END ....C=1000, gamma=1, kernel=linear;, score=0.956 total time=   0.4s\n",
      "[CV 3/5] END ....C=1000, gamma=1, kernel=linear;, score=0.972 total time=   0.1s\n",
      "[CV 4/5] END ....C=1000, gamma=1, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=1, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ......C=1000, gamma=1, kernel=poly;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END ......C=1000, gamma=1, kernel=poly;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END ......C=1000, gamma=1, kernel=poly;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END ......C=1000, gamma=1, kernel=poly;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END ......C=1000, gamma=1, kernel=poly;, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.721 total time=   0.1s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.715 total time=   0.1s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.682 total time=   0.1s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.720 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.194 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.245 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.176 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.230 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.204 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.975 total time=   0.1s\n",
      "[CV 2/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.956 total time=   0.4s\n",
      "[CV 3/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.972 total time=   0.1s\n",
      "[CV 4/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.868 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.890 total time=   0.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.896 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.903 total time=   0.0s\n",
      "[CV 1/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.602 total time=   0.0s\n",
      "[CV 2/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.683 total time=   0.0s\n",
      "[CV 3/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.635 total time=   0.0s\n",
      "[CV 4/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.610 total time=   0.0s\n",
      "[CV 5/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.648 total time=   0.0s\n",
      "[CV 1/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.975 total time=   0.1s\n",
      "[CV 2/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.956 total time=   0.4s\n",
      "[CV 3/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.972 total time=   0.1s\n",
      "[CV 4/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.837 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.806 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.937 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.943 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.956 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=linear;, score=0.975 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=linear;, score=0.956 total time=   0.4s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=linear;, score=0.972 total time=   0.1s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.915 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.928 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.937 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.909 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.943 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.975 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.956 total time=   0.4s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.972 total time=   0.1s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.251 total time=   0.0s\n",
      "[CV 2/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.254 total time=   0.0s\n",
      "[CV 3/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 4/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 5/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.252 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.900 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.915 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.921 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.871 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.881 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: SVC</label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_htuning.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "71742e1a-3db3-44fe-a5e1-92c82e98386d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(svm_htuning.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e721a4-6bc5-4416-bb2c-5ad6c9380d9b",
   "metadata": {},
   "source": [
    "#### SVM Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b3d9f6ef-8b7b-48d0-a8a6-6d6c423720ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9423558897243107"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_svm_classifier = SVC(C=1000,gamma=1,kernel='linear')\n",
    "tuned_svm_classifier.fit(train_data, train_labels)\n",
    "tuned_svm_predictions = tuned_svm_classifier.predict(test_data)\n",
    "accuracy_score(test_labels,tuned_svm_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff55d5-c7ba-4abf-bda4-bc6d82d40d97",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a4a71e8f-5508-4471-83a8-52030437fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb_classifier = gnb.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7e0f74d6-0cc2-4e16-b556-fbae421d25df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8120300751879699"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_predictions = gnb_classifier.predict(test_data)\n",
    "accuracy_score(test_labels,gnb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd2dc19-0d76-4979-8244-db8ff9131dbb",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e96a34c0-6b5b-4075-a251-3760d4a07c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_param_grid = {'var_smoothing': np.logspace(0,-9, num=100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fdeeada3-9f95-45f9-a61b-de3c6fd67aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_htuning = GridSearchCV(GaussianNB(), gnb_param_grid, refit = True, verbose = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5e1b4d82-bae2-4771-b96b-19f0bee9e5e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END .................var_smoothing=1.0;, score=0.630 total time=   0.0s\n",
      "[CV 2/5] END .................var_smoothing=1.0;, score=0.677 total time=   0.0s\n",
      "[CV 3/5] END .................var_smoothing=1.0;, score=0.660 total time=   0.0s\n",
      "[CV 4/5] END .................var_smoothing=1.0;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END .................var_smoothing=1.0;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END ..var_smoothing=0.8111308307896871;, score=0.646 total time=   0.0s\n",
      "[CV 2/5] END ..var_smoothing=0.8111308307896871;, score=0.674 total time=   0.0s\n",
      "[CV 3/5] END ..var_smoothing=0.8111308307896871;, score=0.664 total time=   0.0s\n",
      "[CV 4/5] END ..var_smoothing=0.8111308307896871;, score=0.717 total time=   0.0s\n",
      "[CV 5/5] END ..var_smoothing=0.8111308307896871;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END ...var_smoothing=0.657933224657568;, score=0.652 total time=   0.0s\n",
      "[CV 2/5] END ...var_smoothing=0.657933224657568;, score=0.699 total time=   0.0s\n",
      "[CV 3/5] END ...var_smoothing=0.657933224657568;, score=0.664 total time=   0.0s\n",
      "[CV 4/5] END ...var_smoothing=0.657933224657568;, score=0.726 total time=   0.0s\n",
      "[CV 5/5] END ...var_smoothing=0.657933224657568;, score=0.723 total time=   0.0s\n",
      "[CV 1/5] END ...var_smoothing=0.533669923120631;, score=0.674 total time=   0.0s\n",
      "[CV 2/5] END ...var_smoothing=0.533669923120631;, score=0.702 total time=   0.0s\n",
      "[CV 3/5] END ...var_smoothing=0.533669923120631;, score=0.676 total time=   0.0s\n",
      "[CV 4/5] END ...var_smoothing=0.533669923120631;, score=0.742 total time=   0.0s\n",
      "[CV 5/5] END ...var_smoothing=0.533669923120631;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.43287612810830584;, score=0.690 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.43287612810830584;, score=0.702 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.43287612810830584;, score=0.682 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.43287612810830584;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.43287612810830584;, score=0.752 total time=   0.0s\n",
      "[CV 1/5] END ..var_smoothing=0.3511191734215131;, score=0.699 total time=   0.0s\n",
      "[CV 2/5] END ..var_smoothing=0.3511191734215131;, score=0.699 total time=   0.0s\n",
      "[CV 3/5] END ..var_smoothing=0.3511191734215131;, score=0.698 total time=   0.0s\n",
      "[CV 4/5] END ..var_smoothing=0.3511191734215131;, score=0.770 total time=   0.0s\n",
      "[CV 5/5] END ..var_smoothing=0.3511191734215131;, score=0.755 total time=   0.0s\n",
      "[CV 1/5] END ..var_smoothing=0.2848035868435802;, score=0.718 total time=   0.0s\n",
      "[CV 2/5] END ..var_smoothing=0.2848035868435802;, score=0.696 total time=   0.0s\n",
      "[CV 3/5] END ..var_smoothing=0.2848035868435802;, score=0.720 total time=   0.0s\n",
      "[CV 4/5] END ..var_smoothing=0.2848035868435802;, score=0.780 total time=   0.0s\n",
      "[CV 5/5] END ..var_smoothing=0.2848035868435802;, score=0.764 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.23101297000831597;, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.23101297000831597;, score=0.708 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.23101297000831597;, score=0.739 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.23101297000831597;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.23101297000831597;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END ..var_smoothing=0.1873817422860384;, score=0.737 total time=   0.0s\n",
      "[CV 2/5] END ..var_smoothing=0.1873817422860384;, score=0.724 total time=   0.0s\n",
      "[CV 3/5] END ..var_smoothing=0.1873817422860384;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END ..var_smoothing=0.1873817422860384;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END ..var_smoothing=0.1873817422860384;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.15199110829529336;, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.15199110829529336;, score=0.734 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.15199110829529336;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.15199110829529336;, score=0.799 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.15199110829529336;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.12328467394420659;, score=0.752 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.12328467394420659;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.12328467394420659;, score=0.761 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.12328467394420659;, score=0.808 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.12328467394420659;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END .................var_smoothing=0.1;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END .................var_smoothing=0.1;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END .................var_smoothing=0.1;, score=0.780 total time=   0.0s\n",
      "[CV 4/5] END .................var_smoothing=0.1;, score=0.818 total time=   0.0s\n",
      "[CV 5/5] END .................var_smoothing=0.1;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.08111308307896872;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.08111308307896872;, score=0.765 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.08111308307896872;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.08111308307896872;, score=0.827 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.08111308307896872;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END ..var_smoothing=0.0657933224657568;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END ..var_smoothing=0.0657933224657568;, score=0.762 total time=   0.0s\n",
      "[CV 3/5] END ..var_smoothing=0.0657933224657568;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END ..var_smoothing=0.0657933224657568;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ..var_smoothing=0.0657933224657568;, score=0.802 total time=   0.0s\n",
      "[CV 1/5] END ..var_smoothing=0.0533669923120631;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END ..var_smoothing=0.0533669923120631;, score=0.762 total time=   0.0s\n",
      "[CV 3/5] END ..var_smoothing=0.0533669923120631;, score=0.783 total time=   0.0s\n",
      "[CV 4/5] END ..var_smoothing=0.0533669923120631;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END ..var_smoothing=0.0533669923120631;, score=0.808 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.04328761281083057;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.04328761281083057;, score=0.768 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.04328761281083057;, score=0.783 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.04328761281083057;, score=0.855 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.04328761281083057;, score=0.808 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.03511191734215131;, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.03511191734215131;, score=0.781 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.03511191734215131;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.03511191734215131;, score=0.849 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.03511191734215131;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.02848035868435802;, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.02848035868435802;, score=0.781 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.02848035868435802;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.02848035868435802;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.02848035868435802;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.02310129700083159;, score=0.793 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.02310129700083159;, score=0.790 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.02310129700083159;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.02310129700083159;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.02310129700083159;, score=0.808 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.01873817422860384;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.01873817422860384;, score=0.793 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.01873817422860384;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.01873817422860384;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.01873817422860384;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END .var_smoothing=0.01519911082952933;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END .var_smoothing=0.01519911082952933;, score=0.790 total time=   0.0s\n",
      "[CV 3/5] END .var_smoothing=0.01519911082952933;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END .var_smoothing=0.01519911082952933;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END .var_smoothing=0.01519911082952933;, score=0.814 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.012328467394420659;, score=0.781 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.012328467394420659;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.012328467394420659;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.012328467394420659;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.012328467394420659;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END ................var_smoothing=0.01;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END ................var_smoothing=0.01;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END ................var_smoothing=0.01;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END ................var_smoothing=0.01;, score=0.830 total time=   0.0s\n",
      "[CV 5/5] END ................var_smoothing=0.01;, score=0.814 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.008111308307896872;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.008111308307896872;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.008111308307896872;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.008111308307896872;, score=0.830 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.008111308307896872;, score=0.814 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.006579332246575682;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.006579332246575682;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.006579332246575682;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.006579332246575682;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.006579332246575682;, score=0.814 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.005336699231206307;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.005336699231206307;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.005336699231206307;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.005336699231206307;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.005336699231206307;, score=0.814 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.004328761281083057;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.004328761281083057;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.004328761281083057;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.004328761281083057;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.004328761281083057;, score=0.814 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.003511191734215131;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.003511191734215131;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.003511191734215131;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.003511191734215131;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.003511191734215131;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.002848035868435802;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.002848035868435802;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.002848035868435802;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.002848035868435802;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.002848035868435802;, score=0.808 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0023101297000831605;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0023101297000831605;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0023101297000831605;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0023101297000831605;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0023101297000831605;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.001873817422860383;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.001873817422860383;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.001873817422860383;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.001873817422860383;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.001873817422860383;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0015199110829529332;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0015199110829529332;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0015199110829529332;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0015199110829529332;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0015199110829529332;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0012328467394420659;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0012328467394420659;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0012328467394420659;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0012328467394420659;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0012328467394420659;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END ...............var_smoothing=0.001;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END ...............var_smoothing=0.001;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END ...............var_smoothing=0.001;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END ...............var_smoothing=0.001;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ...............var_smoothing=0.001;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0008111308307896872;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0008111308307896872;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0008111308307896872;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0008111308307896872;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0008111308307896872;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0006579332246575676;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0006579332246575676;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0006579332246575676;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0006579332246575676;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0006579332246575676;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0005336699231206307;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0005336699231206307;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0005336699231206307;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0005336699231206307;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0005336699231206307;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0004328761281083057;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0004328761281083057;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0004328761281083057;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0004328761281083057;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0004328761281083057;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0003511191734215131;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0003511191734215131;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0003511191734215131;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0003511191734215131;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0003511191734215131;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0002848035868435802;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0002848035868435802;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0002848035868435802;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0002848035868435802;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0002848035868435802;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0002310129700083158;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0002310129700083158;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0002310129700083158;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0002310129700083158;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0002310129700083158;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0001873817422860383;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0001873817422860383;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0001873817422860383;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0001873817422860383;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0001873817422860383;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0001519911082952933;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0001519911082952933;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0001519911082952933;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0001519911082952933;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0001519911082952933;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0001232846739442066;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0001232846739442066;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0001232846739442066;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0001232846739442066;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0001232846739442066;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END ..............var_smoothing=0.0001;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END ..............var_smoothing=0.0001;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END ..............var_smoothing=0.0001;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END ..............var_smoothing=0.0001;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ..............var_smoothing=0.0001;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=8.111308307896872e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=8.111308307896872e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=8.111308307896872e-05;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=8.111308307896872e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=8.111308307896872e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=6.579332246575683e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=6.579332246575683e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=6.579332246575683e-05;, score=0.789 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=6.579332246575683e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=6.579332246575683e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=5.3366992312063123e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=5.3366992312063123e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=5.3366992312063123e-05;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=5.3366992312063123e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=5.3366992312063123e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=4.328761281083062e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=4.328761281083062e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=4.328761281083062e-05;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=4.328761281083062e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=4.328761281083062e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=3.511191734215127e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=3.511191734215127e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=3.511191734215127e-05;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=3.511191734215127e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=3.511191734215127e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.848035868435799e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.848035868435799e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.848035868435799e-05;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.848035868435799e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.848035868435799e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.310129700083158e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.310129700083158e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.310129700083158e-05;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.310129700083158e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.310129700083158e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.873817422860383e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.873817422860383e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.873817422860383e-05;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.873817422860383e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.873817422860383e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.5199110829529332e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.5199110829529332e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.5199110829529332e-05;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.5199110829529332e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.5199110829529332e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.2328467394420658e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.2328467394420658e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.2328467394420658e-05;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.2328467394420658e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.2328467394420658e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END ...............var_smoothing=1e-05;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END ...............var_smoothing=1e-05;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END ...............var_smoothing=1e-05;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ...............var_smoothing=1e-05;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ...............var_smoothing=1e-05;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=8.111308307896873e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=8.111308307896873e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=8.111308307896873e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=8.111308307896873e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=8.111308307896873e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=6.579332246575683e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=6.579332246575683e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=6.579332246575683e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=6.579332246575683e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=6.579332246575683e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=5.336699231206313e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=5.336699231206313e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=5.336699231206313e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=5.336699231206313e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=5.336699231206313e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=4.328761281083053e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=4.328761281083053e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=4.328761281083053e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=4.328761281083053e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=4.328761281083053e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=3.5111917342151275e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=3.5111917342151275e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=3.5111917342151275e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=3.5111917342151275e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=3.5111917342151275e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.848035868435799e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.848035868435799e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.848035868435799e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.848035868435799e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.848035868435799e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.310129700083158e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.310129700083158e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.310129700083158e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.310129700083158e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.310129700083158e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.873817422860383e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.873817422860383e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.873817422860383e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.873817422860383e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.873817422860383e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.519911082952933e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.519911082952933e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.519911082952933e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.519911082952933e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.519911082952933e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.232846739442066e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.232846739442066e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.232846739442066e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.232846739442066e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.232846739442066e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END ...............var_smoothing=1e-06;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END ...............var_smoothing=1e-06;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END ...............var_smoothing=1e-06;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ...............var_smoothing=1e-06;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ...............var_smoothing=1e-06;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=8.111308307896872e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=8.111308307896872e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=8.111308307896872e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=8.111308307896872e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=8.111308307896872e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=6.579332246575682e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=6.579332246575682e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=6.579332246575682e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=6.579332246575682e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=6.579332246575682e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=5.336699231206313e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=5.336699231206313e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=5.336699231206313e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=5.336699231206313e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=5.336699231206313e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=4.3287612810830526e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=4.3287612810830526e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=4.3287612810830526e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=4.3287612810830526e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=4.3287612810830526e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=3.5111917342151277e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=3.5111917342151277e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=3.5111917342151277e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=3.5111917342151277e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=3.5111917342151277e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.848035868435799e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.848035868435799e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.848035868435799e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.848035868435799e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.848035868435799e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.310129700083158e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.310129700083158e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.310129700083158e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.310129700083158e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.310129700083158e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.873817422860383e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.873817422860383e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.873817422860383e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.873817422860383e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.873817422860383e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.519911082952933e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.519911082952933e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.519911082952933e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.519911082952933e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.519911082952933e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.232846739442066e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.232846739442066e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.232846739442066e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.232846739442066e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.232846739442066e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END ...............var_smoothing=1e-07;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END ...............var_smoothing=1e-07;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END ...............var_smoothing=1e-07;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ...............var_smoothing=1e-07;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ...............var_smoothing=1e-07;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=8.111308307896873e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=8.111308307896873e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=8.111308307896873e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=8.111308307896873e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=8.111308307896873e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=6.579332246575682e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=6.579332246575682e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=6.579332246575682e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=6.579332246575682e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=6.579332246575682e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=5.336699231206302e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=5.336699231206302e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=5.336699231206302e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=5.336699231206302e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=5.336699231206302e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=4.3287612810830526e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=4.3287612810830526e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=4.3287612810830526e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=4.3287612810830526e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=4.3287612810830526e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=3.5111917342151277e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=3.5111917342151277e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=3.5111917342151277e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=3.5111917342151277e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=3.5111917342151277e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.848035868435799e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.848035868435799e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.848035868435799e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.848035868435799e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.848035868435799e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.310129700083158e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.310129700083158e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.310129700083158e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.310129700083158e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.310129700083158e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.873817422860383e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.873817422860383e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.873817422860383e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.873817422860383e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.873817422860383e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.519911082952933e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.519911082952933e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.519911082952933e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.519911082952933e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.519911082952933e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.232846739442066e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.232846739442066e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.232846739442066e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.232846739442066e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.232846739442066e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END ...............var_smoothing=1e-08;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END ...............var_smoothing=1e-08;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END ...............var_smoothing=1e-08;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ...............var_smoothing=1e-08;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ...............var_smoothing=1e-08;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=8.111308307896856e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=8.111308307896856e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=8.111308307896856e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=8.111308307896856e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=8.111308307896856e-09;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=6.579332246575682e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=6.579332246575682e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=6.579332246575682e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=6.579332246575682e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=6.579332246575682e-09;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=5.336699231206302e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=5.336699231206302e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=5.336699231206302e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=5.336699231206302e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=5.336699231206302e-09;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=4.328761281083061e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=4.328761281083061e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=4.328761281083061e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=4.328761281083061e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=4.328761281083061e-09;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=3.5111917342151273e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=3.5111917342151273e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=3.5111917342151273e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=3.5111917342151273e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=3.5111917342151273e-09;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.848035868435805e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.848035868435805e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.848035868435805e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.848035868435805e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.848035868435805e-09;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.310129700083158e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.310129700083158e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.310129700083158e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.310129700083158e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.310129700083158e-09;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.873817422860387e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.873817422860387e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.873817422860387e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.873817422860387e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.873817422860387e-09;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.519911082952933e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.519911082952933e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.519911082952933e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.519911082952933e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.519911082952933e-09;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.2328467394420635e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.2328467394420635e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.2328467394420635e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.2328467394420635e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.2328467394420635e-09;, score=0.811 total time=   0.0s\n",
      "[CV 1/5] END ...............var_smoothing=1e-09;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END ...............var_smoothing=1e-09;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END ...............var_smoothing=1e-09;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ...............var_smoothing=1e-09;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ...............var_smoothing=1e-09;, score=0.811 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3101297...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3101297...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: GaussianNB</label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GaussianNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3101297...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_htuning.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a7fd986a-3ea5-4940-abe2-9117fa048369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.02310129700083159}\n"
     ]
    }
   ],
   "source": [
    "print(gnb_htuning.best_params_) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d0542-d623-4477-8dd9-0f4fd9d47c05",
   "metadata": {},
   "source": [
    "#### Naive Bayes Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e753e9e7-9ff6-40c6-9f48-d7be24100c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8295739348370927"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_gnb_classifier = GaussianNB(var_smoothing= 0.02310129700083159)\n",
    "tuned_gnb_classifier.fit(train_data, train_labels)\n",
    "tuned_gnb_predictions = tuned_gnb_classifier.predict(test_data)\n",
    "accuracy_score(test_labels,tuned_gnb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b58538-1023-471f-8f30-978a0887a082",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "95f95d12-cca1-4744-b218-a4814079f217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "58a6d664-0390-4932-8efe-b3831d1b82d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9097744360902256"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_predictions = lr_classifier.predict(test_data)\n",
    "accuracy_score(test_labels,lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d4b56-3d98-4231-ae64-af75c145a603",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "076b7d1d-c91f-458e-a9a2-dbbfd32be647",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {'C': np.logspace(-4, 4, 50),  \n",
    "              'penalty': ['l1', 'l2']}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f59de832-8308-4db1-a898-3f8869536606",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_htuning = GridSearchCV(LogisticRegression(), lr_param_grid, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "95b52c51-4005-40db-9a7b-4628188ae9d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END ................C=0.0001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ................C=0.0001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ................C=0.0001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ................C=0.0001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ................C=0.0001, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..............C=0.0001, penalty=l2;, score=0.285 total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.0001, penalty=l2;, score=0.414 total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.0001, penalty=l2;, score=0.349 total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.0001, penalty=l2;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.0001, penalty=l2;, score=0.314 total time=   0.0s\n",
      "[CV 1/5] END C=0.00014563484775012445, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.00014563484775012445, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.00014563484775012445, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.00014563484775012445, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.00014563484775012445, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.00014563484775012445, penalty=l2;, score=0.354 total time=   0.0s\n",
      "[CV 2/5] END C=0.00014563484775012445, penalty=l2;, score=0.517 total time=   0.0s\n",
      "[CV 3/5] END C=0.00014563484775012445, penalty=l2;, score=0.415 total time=   0.0s\n",
      "[CV 4/5] END C=0.00014563484775012445, penalty=l2;, score=0.465 total time=   0.0s\n",
      "[CV 5/5] END C=0.00014563484775012445, penalty=l2;, score=0.472 total time=   0.0s\n",
      "[CV 1/5] END C=0.00021209508879201905, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.00021209508879201905, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.00021209508879201905, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.00021209508879201905, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.00021209508879201905, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.00021209508879201905, penalty=l2;, score=0.467 total time=   0.0s\n",
      "[CV 2/5] END C=0.00021209508879201905, penalty=l2;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END C=0.00021209508879201905, penalty=l2;, score=0.522 total time=   0.0s\n",
      "[CV 4/5] END C=0.00021209508879201905, penalty=l2;, score=0.553 total time=   0.0s\n",
      "[CV 5/5] END C=0.00021209508879201905, penalty=l2;, score=0.619 total time=   0.0s\n",
      "[CV 1/5] END C=0.00030888435964774815, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.00030888435964774815, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.00030888435964774815, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.00030888435964774815, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.00030888435964774815, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.00030888435964774815, penalty=l2;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END C=0.00030888435964774815, penalty=l2;, score=0.542 total time=   0.0s\n",
      "[CV 3/5] END C=0.00030888435964774815, penalty=l2;, score=0.572 total time=   0.0s\n",
      "[CV 4/5] END C=0.00030888435964774815, penalty=l2;, score=0.594 total time=   0.0s\n",
      "[CV 5/5] END C=0.00030888435964774815, penalty=l2;, score=0.616 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0004498432668969444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=0.0004498432668969444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=0.0004498432668969444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=0.0004498432668969444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=0.0004498432668969444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0004498432668969444, penalty=l2;, score=0.530 total time=   0.0s\n",
      "[CV 2/5] END C=0.0004498432668969444, penalty=l2;, score=0.542 total time=   0.0s\n",
      "[CV 3/5] END C=0.0004498432668969444, penalty=l2;, score=0.585 total time=   0.0s\n",
      "[CV 4/5] END C=0.0004498432668969444, penalty=l2;, score=0.610 total time=   0.0s\n",
      "[CV 5/5] END C=0.0004498432668969444, penalty=l2;, score=0.610 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0006551285568595509, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=0.0006551285568595509, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=0.0006551285568595509, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=0.0006551285568595509, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=0.0006551285568595509, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0006551285568595509, penalty=l2;, score=0.530 total time=   0.0s\n",
      "[CV 2/5] END C=0.0006551285568595509, penalty=l2;, score=0.542 total time=   0.0s\n",
      "[CV 3/5] END C=0.0006551285568595509, penalty=l2;, score=0.582 total time=   0.0s\n",
      "[CV 4/5] END C=0.0006551285568595509, penalty=l2;, score=0.591 total time=   0.0s\n",
      "[CV 5/5] END C=0.0006551285568595509, penalty=l2;, score=0.604 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0009540954763499944, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=0.0009540954763499944, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=0.0009540954763499944, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=0.0009540954763499944, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=0.0009540954763499944, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0009540954763499944, penalty=l2;, score=0.536 total time=   0.0s\n",
      "[CV 2/5] END C=0.0009540954763499944, penalty=l2;, score=0.539 total time=   0.0s\n",
      "[CV 3/5] END C=0.0009540954763499944, penalty=l2;, score=0.601 total time=   0.0s\n",
      "[CV 4/5] END C=0.0009540954763499944, penalty=l2;, score=0.591 total time=   0.0s\n",
      "[CV 5/5] END C=0.0009540954763499944, penalty=l2;, score=0.597 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0013894954943731374, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=0.0013894954943731374, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=0.0013894954943731374, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=0.0013894954943731374, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=0.0013894954943731374, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0013894954943731374, penalty=l2;, score=0.542 total time=   0.0s\n",
      "[CV 2/5] END C=0.0013894954943731374, penalty=l2;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END C=0.0013894954943731374, penalty=l2;, score=0.616 total time=   0.0s\n",
      "[CV 4/5] END C=0.0013894954943731374, penalty=l2;, score=0.594 total time=   0.0s\n",
      "[CV 5/5] END C=0.0013894954943731374, penalty=l2;, score=0.604 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0020235896477251557, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=0.0020235896477251557, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=0.0020235896477251557, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=0.0020235896477251557, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=0.0020235896477251557, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0020235896477251557, penalty=l2;, score=0.558 total time=   0.0s\n",
      "[CV 2/5] END C=0.0020235896477251557, penalty=l2;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END C=0.0020235896477251557, penalty=l2;, score=0.616 total time=   0.0s\n",
      "[CV 4/5] END C=0.0020235896477251557, penalty=l2;, score=0.597 total time=   0.0s\n",
      "[CV 5/5] END C=0.0020235896477251557, penalty=l2;, score=0.601 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0029470517025518097, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=0.0029470517025518097, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=0.0029470517025518097, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=0.0029470517025518097, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=0.0029470517025518097, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0029470517025518097, penalty=l2;, score=0.558 total time=   0.0s\n",
      "[CV 2/5] END C=0.0029470517025518097, penalty=l2;, score=0.536 total time=   0.0s\n",
      "[CV 3/5] END C=0.0029470517025518097, penalty=l2;, score=0.623 total time=   0.0s\n",
      "[CV 4/5] END C=0.0029470517025518097, penalty=l2;, score=0.613 total time=   0.0s\n",
      "[CV 5/5] END C=0.0029470517025518097, penalty=l2;, score=0.607 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.004291934260128779, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.004291934260128779, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.004291934260128779, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.004291934260128779, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.004291934260128779, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.004291934260128779, penalty=l2;, score=0.561 total time=   0.0s\n",
      "[CV 2/5] END C=0.004291934260128779, penalty=l2;, score=0.545 total time=   0.0s\n",
      "[CV 3/5] END C=0.004291934260128779, penalty=l2;, score=0.619 total time=   0.0s\n",
      "[CV 4/5] END C=0.004291934260128779, penalty=l2;, score=0.616 total time=   0.0s\n",
      "[CV 5/5] END C=0.004291934260128779, penalty=l2;, score=0.619 total time=   0.0s\n",
      "[CV 1/5] END .C=0.0062505519252739694, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=0.0062505519252739694, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=0.0062505519252739694, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=0.0062505519252739694, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=0.0062505519252739694, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.0062505519252739694, penalty=l2;, score=0.571 total time=   0.0s\n",
      "[CV 2/5] END C=0.0062505519252739694, penalty=l2;, score=0.561 total time=   0.0s\n",
      "[CV 3/5] END C=0.0062505519252739694, penalty=l2;, score=0.616 total time=   0.0s\n",
      "[CV 4/5] END C=0.0062505519252739694, penalty=l2;, score=0.619 total time=   0.0s\n",
      "[CV 5/5] END C=0.0062505519252739694, penalty=l2;, score=0.626 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.009102981779915217, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.009102981779915217, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.009102981779915217, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.009102981779915217, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.009102981779915217, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.009102981779915217, penalty=l2;, score=0.580 total time=   0.0s\n",
      "[CV 2/5] END C=0.009102981779915217, penalty=l2;, score=0.577 total time=   0.0s\n",
      "[CV 3/5] END C=0.009102981779915217, penalty=l2;, score=0.619 total time=   0.0s\n",
      "[CV 4/5] END C=0.009102981779915217, penalty=l2;, score=0.619 total time=   0.0s\n",
      "[CV 5/5] END C=0.009102981779915217, penalty=l2;, score=0.626 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.013257113655901081, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.013257113655901081, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.013257113655901081, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.013257113655901081, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.013257113655901081, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.013257113655901081, penalty=l2;, score=0.577 total time=   0.0s\n",
      "[CV 2/5] END C=0.013257113655901081, penalty=l2;, score=0.592 total time=   0.0s\n",
      "[CV 3/5] END C=0.013257113655901081, penalty=l2;, score=0.626 total time=   0.0s\n",
      "[CV 4/5] END C=0.013257113655901081, penalty=l2;, score=0.619 total time=   0.0s\n",
      "[CV 5/5] END C=0.013257113655901081, penalty=l2;, score=0.642 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.019306977288832496, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.019306977288832496, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.019306977288832496, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.019306977288832496, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.019306977288832496, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.019306977288832496, penalty=l2;, score=0.599 total time=   0.0s\n",
      "[CV 2/5] END C=0.019306977288832496, penalty=l2;, score=0.611 total time=   0.0s\n",
      "[CV 3/5] END C=0.019306977288832496, penalty=l2;, score=0.635 total time=   0.0s\n",
      "[CV 4/5] END C=0.019306977288832496, penalty=l2;, score=0.635 total time=   0.0s\n",
      "[CV 5/5] END C=0.019306977288832496, penalty=l2;, score=0.664 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.02811768697974228, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.02811768697974228, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.02811768697974228, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.02811768697974228, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.02811768697974228, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.02811768697974228, penalty=l2;, score=0.627 total time=   0.0s\n",
      "[CV 2/5] END .C=0.02811768697974228, penalty=l2;, score=0.633 total time=   0.0s\n",
      "[CV 3/5] END .C=0.02811768697974228, penalty=l2;, score=0.667 total time=   0.0s\n",
      "[CV 4/5] END .C=0.02811768697974228, penalty=l2;, score=0.651 total time=   0.0s\n",
      "[CV 5/5] END .C=0.02811768697974228, penalty=l2;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.040949150623804234, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.040949150623804234, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.040949150623804234, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.040949150623804234, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.040949150623804234, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.040949150623804234, penalty=l2;, score=0.649 total time=   0.0s\n",
      "[CV 2/5] END C=0.040949150623804234, penalty=l2;, score=0.661 total time=   0.0s\n",
      "[CV 3/5] END C=0.040949150623804234, penalty=l2;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END C=0.040949150623804234, penalty=l2;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END C=0.040949150623804234, penalty=l2;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.05963623316594643, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.05963623316594643, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.05963623316594643, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.05963623316594643, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.05963623316594643, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.05963623316594643, penalty=l2;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END .C=0.05963623316594643, penalty=l2;, score=0.683 total time=   0.0s\n",
      "[CV 3/5] END .C=0.05963623316594643, penalty=l2;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END .C=0.05963623316594643, penalty=l2;, score=0.711 total time=   0.0s\n",
      "[CV 5/5] END .C=0.05963623316594643, penalty=l2;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.08685113737513521, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.08685113737513521, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.08685113737513521, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.08685113737513521, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.08685113737513521, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.08685113737513521, penalty=l2;, score=0.712 total time=   0.0s\n",
      "[CV 2/5] END .C=0.08685113737513521, penalty=l2;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END .C=0.08685113737513521, penalty=l2;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END .C=0.08685113737513521, penalty=l2;, score=0.726 total time=   0.0s\n",
      "[CV 5/5] END .C=0.08685113737513521, penalty=l2;, score=0.739 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.12648552168552957, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.12648552168552957, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.12648552168552957, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.12648552168552957, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.12648552168552957, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.12648552168552957, penalty=l2;, score=0.730 total time=   0.0s\n",
      "[CV 2/5] END .C=0.12648552168552957, penalty=l2;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END .C=0.12648552168552957, penalty=l2;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END .C=0.12648552168552957, penalty=l2;, score=0.777 total time=   0.0s\n",
      "[CV 5/5] END .C=0.12648552168552957, penalty=l2;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.18420699693267145, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.18420699693267145, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.18420699693267145, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.18420699693267145, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.18420699693267145, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.18420699693267145, penalty=l2;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END .C=0.18420699693267145, penalty=l2;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END .C=0.18420699693267145, penalty=l2;, score=0.761 total time=   0.0s\n",
      "[CV 4/5] END .C=0.18420699693267145, penalty=l2;, score=0.796 total time=   0.0s\n",
      "[CV 5/5] END .C=0.18420699693267145, penalty=l2;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.2682695795279725, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.2682695795279725, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.2682695795279725, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.2682695795279725, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.2682695795279725, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=0.2682695795279725, penalty=l2;, score=0.781 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.2682695795279725, penalty=l2;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.2682695795279725, penalty=l2;, score=0.774 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.2682695795279725, penalty=l2;, score=0.808 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.2682695795279725, penalty=l2;, score=0.821 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.3906939937054613, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.3906939937054613, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.3906939937054613, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.3906939937054613, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.3906939937054613, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=0.3906939937054613, penalty=l2;, score=0.790 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.3906939937054613, penalty=l2;, score=0.853 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.3906939937054613, penalty=l2;, score=0.802 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.3906939937054613, penalty=l2;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.3906939937054613, penalty=l2;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.5689866029018293, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.5689866029018293, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.5689866029018293, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.5689866029018293, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.5689866029018293, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=0.5689866029018293, penalty=l2;, score=0.809 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.5689866029018293, penalty=l2;, score=0.865 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.5689866029018293, penalty=l2;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.5689866029018293, penalty=l2;, score=0.855 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.5689866029018293, penalty=l2;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.8286427728546842, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.8286427728546842, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.8286427728546842, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.8286427728546842, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.8286427728546842, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=0.8286427728546842, penalty=l2;, score=0.843 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.8286427728546842, penalty=l2;, score=0.890 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.8286427728546842, penalty=l2;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.8286427728546842, penalty=l2;, score=0.874 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.8286427728546842, penalty=l2;, score=0.887 total time=   0.0s\n",
      "[CV 1/5] END ....C=1.2067926406393288, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=1.2067926406393288, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=1.2067926406393288, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=1.2067926406393288, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=1.2067926406393288, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=1.2067926406393288, penalty=l2;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END ..C=1.2067926406393288, penalty=l2;, score=0.915 total time=   0.0s\n",
      "[CV 3/5] END ..C=1.2067926406393288, penalty=l2;, score=0.899 total time=   0.0s\n",
      "[CV 4/5] END ..C=1.2067926406393288, penalty=l2;, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END ..C=1.2067926406393288, penalty=l2;, score=0.928 total time=   0.0s\n",
      "[CV 1/5] END ....C=1.7575106248547894, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=1.7575106248547894, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=1.7575106248547894, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=1.7575106248547894, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=1.7575106248547894, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=1.7575106248547894, penalty=l2;, score=0.903 total time=   0.0s\n",
      "[CV 2/5] END ..C=1.7575106248547894, penalty=l2;, score=0.931 total time=   0.0s\n",
      "[CV 3/5] END ..C=1.7575106248547894, penalty=l2;, score=0.921 total time=   0.0s\n",
      "[CV 4/5] END ..C=1.7575106248547894, penalty=l2;, score=0.906 total time=   0.0s\n",
      "[CV 5/5] END ..C=1.7575106248547894, penalty=l2;, score=0.940 total time=   0.0s\n",
      "[CV 1/5] END .....C=2.559547922699533, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=2.559547922699533, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=2.559547922699533, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=2.559547922699533, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=2.559547922699533, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=2.559547922699533, penalty=l2;, score=0.915 total time=   0.0s\n",
      "[CV 2/5] END ...C=2.559547922699533, penalty=l2;, score=0.940 total time=   0.0s\n",
      "[CV 3/5] END ...C=2.559547922699533, penalty=l2;, score=0.928 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=2.559547922699533, penalty=l2;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END ...C=2.559547922699533, penalty=l2;, score=0.953 total time=   0.0s\n",
      "[CV 1/5] END .....C=3.727593720314938, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=3.727593720314938, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=3.727593720314938, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=3.727593720314938, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=3.727593720314938, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=3.727593720314938, penalty=l2;, score=0.925 total time=   0.0s\n",
      "[CV 2/5] END ...C=3.727593720314938, penalty=l2;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ...C=3.727593720314938, penalty=l2;, score=0.934 total time=   0.0s\n",
      "[CV 4/5] END ...C=3.727593720314938, penalty=l2;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END ...C=3.727593720314938, penalty=l2;, score=0.959 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .....C=5.428675439323859, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=5.428675439323859, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=5.428675439323859, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=5.428675439323859, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=5.428675439323859, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=5.428675439323859, penalty=l2;, score=0.931 total time=   0.0s\n",
      "[CV 2/5] END ...C=5.428675439323859, penalty=l2;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ...C=5.428675439323859, penalty=l2;, score=0.934 total time=   0.0s\n",
      "[CV 4/5] END ...C=5.428675439323859, penalty=l2;, score=0.931 total time=   0.0s\n",
      "[CV 5/5] END ...C=5.428675439323859, penalty=l2;, score=0.956 total time=   0.0s\n",
      "[CV 1/5] END ....C=7.9060432109076855, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=7.9060432109076855, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=7.9060432109076855, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=7.9060432109076855, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=7.9060432109076855, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=7.9060432109076855, penalty=l2;, score=0.944 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=7.9060432109076855, penalty=l2;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ..C=7.9060432109076855, penalty=l2;, score=0.943 total time=   0.0s\n",
      "[CV 4/5] END ..C=7.9060432109076855, penalty=l2;, score=0.937 total time=   0.0s\n",
      "[CV 5/5] END ..C=7.9060432109076855, penalty=l2;, score=0.959 total time=   0.0s\n",
      "[CV 1/5] END ....C=11.513953993264458, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=11.513953993264458, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=11.513953993264458, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=11.513953993264458, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=11.513953993264458, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=11.513953993264458, penalty=l2;, score=0.953 total time=   0.0s\n",
      "[CV 2/5] END ..C=11.513953993264458, penalty=l2;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END ..C=11.513953993264458, penalty=l2;, score=0.943 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=11.513953993264458, penalty=l2;, score=0.950 total time=   0.0s\n",
      "[CV 5/5] END ..C=11.513953993264458, penalty=l2;, score=0.959 total time=   0.0s\n",
      "[CV 1/5] END ....C=16.768329368110066, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=16.768329368110066, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=16.768329368110066, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=16.768329368110066, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=16.768329368110066, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=16.768329368110066, penalty=l2;, score=0.953 total time=   0.0s\n",
      "[CV 2/5] END ..C=16.768329368110066, penalty=l2;, score=0.947 total time=   0.0s\n",
      "[CV 3/5] END ..C=16.768329368110066, penalty=l2;, score=0.956 total time=   0.0s\n",
      "[CV 4/5] END ..C=16.768329368110066, penalty=l2;, score=0.950 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=16.768329368110066, penalty=l2;, score=0.965 total time=   0.0s\n",
      "[CV 1/5] END ....C=24.420530945486497, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=24.420530945486497, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=24.420530945486497, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=24.420530945486497, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=24.420530945486497, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=24.420530945486497, penalty=l2;, score=0.966 total time=   0.0s\n",
      "[CV 2/5] END ..C=24.420530945486497, penalty=l2;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END ..C=24.420530945486497, penalty=l2;, score=0.962 total time=   0.0s\n",
      "[CV 4/5] END ..C=24.420530945486497, penalty=l2;, score=0.947 total time=   0.0s\n",
      "[CV 5/5] END ..C=24.420530945486497, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ....C=35.564803062231285, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=35.564803062231285, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=35.564803062231285, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=35.564803062231285, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=35.564803062231285, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=35.564803062231285, penalty=l2;, score=0.966 total time=   0.0s\n",
      "[CV 2/5] END ..C=35.564803062231285, penalty=l2;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ..C=35.564803062231285, penalty=l2;, score=0.965 total time=   0.0s\n",
      "[CV 4/5] END ..C=35.564803062231285, penalty=l2;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END ..C=35.564803062231285, penalty=l2;, score=0.972 total time=   0.0s\n",
      "[CV 1/5] END .....C=51.79474679231202, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=51.79474679231202, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=51.79474679231202, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=51.79474679231202, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=51.79474679231202, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=51.79474679231202, penalty=l2;, score=0.962 total time=   0.0s\n",
      "[CV 2/5] END ...C=51.79474679231202, penalty=l2;, score=0.953 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=51.79474679231202, penalty=l2;, score=0.965 total time=   0.0s\n",
      "[CV 4/5] END ...C=51.79474679231202, penalty=l2;, score=0.962 total time=   0.0s\n",
      "[CV 5/5] END ...C=51.79474679231202, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END .....C=75.43120063354607, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=75.43120063354607, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=75.43120063354607, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=75.43120063354607, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=75.43120063354607, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=75.43120063354607, penalty=l2;, score=0.978 total time=   0.0s\n",
      "[CV 2/5] END ...C=75.43120063354607, penalty=l2;, score=0.953 total time=   0.0s\n",
      "[CV 3/5] END ...C=75.43120063354607, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END ...C=75.43120063354607, penalty=l2;, score=0.965 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=75.43120063354607, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END ....C=109.85411419875572, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=109.85411419875572, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=109.85411419875572, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=109.85411419875572, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=109.85411419875572, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=109.85411419875572, penalty=l2;, score=0.978 total time=   0.0s\n",
      "[CV 2/5] END ..C=109.85411419875572, penalty=l2;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ..C=109.85411419875572, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END ..C=109.85411419875572, penalty=l2;, score=0.956 total time=   0.0s\n",
      "[CV 5/5] END ..C=109.85411419875572, penalty=l2;, score=0.978 total time=   0.0s\n",
      "[CV 1/5] END ....C=159.98587196060572, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=159.98587196060572, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=159.98587196060572, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=159.98587196060572, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=159.98587196060572, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=159.98587196060572, penalty=l2;, score=0.969 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=159.98587196060572, penalty=l2;, score=0.956 total time=   0.0s\n",
      "[CV 3/5] END ..C=159.98587196060572, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END ..C=159.98587196060572, penalty=l2;, score=0.959 total time=   0.0s\n",
      "[CV 5/5] END ..C=159.98587196060572, penalty=l2;, score=0.978 total time=   0.0s\n",
      "[CV 1/5] END ....C=232.99518105153672, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=232.99518105153672, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=232.99518105153672, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=232.99518105153672, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=232.99518105153672, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=232.99518105153672, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END ..C=232.99518105153672, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END ..C=232.99518105153672, penalty=l2;, score=0.972 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=232.99518105153672, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END ..C=232.99518105153672, penalty=l2;, score=0.978 total time=   0.0s\n",
      "[CV 1/5] END .....C=339.3221771895323, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=339.3221771895323, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=339.3221771895323, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=339.3221771895323, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=339.3221771895323, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=339.3221771895323, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 2/5] END ...C=339.3221771895323, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END ...C=339.3221771895323, penalty=l2;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END ...C=339.3221771895323, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END ...C=339.3221771895323, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END .....C=494.1713361323828, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=494.1713361323828, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=494.1713361323828, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=494.1713361323828, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=494.1713361323828, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=494.1713361323828, penalty=l2;, score=0.972 total time=   0.0s\n",
      "[CV 2/5] END ...C=494.1713361323828, penalty=l2;, score=0.966 total time=   0.0s\n",
      "[CV 3/5] END ...C=494.1713361323828, penalty=l2;, score=0.965 total time=   0.0s\n",
      "[CV 4/5] END ...C=494.1713361323828, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END ...C=494.1713361323828, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END .....C=719.6856730011514, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=719.6856730011514, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=719.6856730011514, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=719.6856730011514, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=719.6856730011514, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=719.6856730011514, penalty=l2;, score=0.978 total time=   0.0s\n",
      "[CV 2/5] END ...C=719.6856730011514, penalty=l2;, score=0.972 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=719.6856730011514, penalty=l2;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END ...C=719.6856730011514, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END ...C=719.6856730011514, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END ....C=1048.1131341546852, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=1048.1131341546852, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=1048.1131341546852, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=1048.1131341546852, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=1048.1131341546852, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=1048.1131341546852, penalty=l2;, score=0.972 total time=   0.0s\n",
      "[CV 2/5] END ..C=1048.1131341546852, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END ..C=1048.1131341546852, penalty=l2;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END ..C=1048.1131341546852, penalty=l2;, score=0.965 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=1048.1131341546852, penalty=l2;, score=0.978 total time=   0.0s\n",
      "[CV 1/5] END ....C=1526.4179671752302, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=1526.4179671752302, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=1526.4179671752302, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=1526.4179671752302, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=1526.4179671752302, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=1526.4179671752302, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END ..C=1526.4179671752302, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 3/5] END ..C=1526.4179671752302, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END ..C=1526.4179671752302, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END ..C=1526.4179671752302, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END .....C=2222.996482526191, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=2222.996482526191, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=2222.996482526191, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=2222.996482526191, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=2222.996482526191, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=2222.996482526191, penalty=l2;, score=0.975 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=2222.996482526191, penalty=l2;, score=0.962 total time=   0.0s\n",
      "[CV 3/5] END ...C=2222.996482526191, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END ...C=2222.996482526191, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 5/5] END ...C=2222.996482526191, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 1/5] END ......C=3237.45754281764, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=3237.45754281764, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=3237.45754281764, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=3237.45754281764, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=3237.45754281764, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=3237.45754281764, penalty=l2;, score=0.978 total time=   0.0s\n",
      "[CV 2/5] END ....C=3237.45754281764, penalty=l2;, score=0.969 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=3237.45754281764, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END ....C=3237.45754281764, penalty=l2;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END ....C=3237.45754281764, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 1/5] END ....C=4714.8663634573895, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=4714.8663634573895, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=4714.8663634573895, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=4714.8663634573895, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=4714.8663634573895, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=4714.8663634573895, penalty=l2;, score=0.981 total time=   0.0s\n",
      "[CV 2/5] END ..C=4714.8663634573895, penalty=l2;, score=0.959 total time=   0.0s\n",
      "[CV 3/5] END ..C=4714.8663634573895, penalty=l2;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END ..C=4714.8663634573895, penalty=l2;, score=0.972 total time=   0.0s\n",
      "[CV 5/5] END ..C=4714.8663634573895, penalty=l2;, score=0.962 total time=   0.0s\n",
      "[CV 1/5] END .....C=6866.488450042998, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=6866.488450042998, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=6866.488450042998, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=6866.488450042998, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=6866.488450042998, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=6866.488450042998, penalty=l2;, score=0.978 total time=   0.0s\n",
      "[CV 2/5] END ...C=6866.488450042998, penalty=l2;, score=0.959 total time=   0.0s\n",
      "[CV 3/5] END ...C=6866.488450042998, penalty=l2;, score=0.972 total time=   0.0s\n",
      "[CV 4/5] END ...C=6866.488450042998, penalty=l2;, score=0.969 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=6866.488450042998, penalty=l2;, score=0.962 total time=   0.0s\n",
      "[CV 1/5] END ...............C=10000.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...............C=10000.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...............C=10000.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...............C=10000.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...............C=10000.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .............C=10000.0, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 2/5] END .............C=10000.0, penalty=l2;, score=0.959 total time=   0.0s\n",
      "[CV 3/5] END .............C=10000.0, penalty=l2;, score=0.975 total time=   0.0s\n",
      "[CV 4/5] END .............C=10000.0, penalty=l2;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END .............C=10000.0, penalty=l2;, score=0.972 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:542: FitFailedWarning: \n",
      "250 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.33918298        nan 0.44473492        nan 0.53899371\n",
      "        nan 0.56663512        nan 0.57542635        nan 0.56976597\n",
      "        nan 0.57290866        nan 0.5779401         nan 0.5810749\n",
      "        nan 0.58736224        nan 0.5923858         nan 0.59865933\n",
      "        nan 0.60430394        nan 0.61121429        nan 0.62879872\n",
      "        nan 0.65015083        nan 0.670874          nan 0.69851344\n",
      "        nan 0.72676801        nan 0.75755604        nan 0.78141007\n",
      "        nan 0.80150628        nan 0.82789771        nan 0.84737485\n",
      "        nan 0.87438142        nan 0.89950316        nan 0.92023028\n",
      "        nan 0.92965044        nan 0.934674          nan 0.93907257\n",
      "        nan 0.945354          nan 0.95163147        nan 0.95415114\n",
      "        nan 0.95917076        nan 0.96294237        nan 0.96357524\n",
      "        nan 0.9679679         nan 0.967337          nan 0.96608505\n",
      "        nan 0.97236253        nan 0.97047968        nan 0.97047968\n",
      "        nan 0.97424538        nan 0.97110664        nan 0.97110467\n",
      "        nan 0.97110861        nan 0.9711027         nan 0.96921985\n",
      "        nan 0.96796396        nan 0.96985272]\n",
      "  warnings.warn(\n",
      "C:\\Users\\abdel\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,\n",
       "       4.49843267e-04, 6.55128557e-04, 9.54095476e-04, 1.38949549e-03,\n",
       "       2.02358965e-03, 2.94705170e-03, 4.29193426e-03, 6.25055193e-03,\n",
       "       9.10298178e-03, 1.32571137e-02, 1.93069773e-02, 2.81176870e-02,\n",
       "       4.09491506e-02, 5.96362332e-02, 8.68511374e-0...\n",
       "       3.72759372e+00, 5.42867544e+00, 7.90604321e+00, 1.15139540e+01,\n",
       "       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n",
       "       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n",
       "       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n",
       "       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n",
       "       6.86648845e+03, 1.00000000e+04]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,\n",
       "       4.49843267e-04, 6.55128557e-04, 9.54095476e-04, 1.38949549e-03,\n",
       "       2.02358965e-03, 2.94705170e-03, 4.29193426e-03, 6.25055193e-03,\n",
       "       9.10298178e-03, 1.32571137e-02, 1.93069773e-02, 2.81176870e-02,\n",
       "       4.09491506e-02, 5.96362332e-02, 8.68511374e-0...\n",
       "       3.72759372e+00, 5.42867544e+00, 7.90604321e+00, 1.15139540e+01,\n",
       "       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n",
       "       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n",
       "       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n",
       "       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n",
       "       6.86648845e+03, 1.00000000e+04]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,\n",
       "       4.49843267e-04, 6.55128557e-04, 9.54095476e-04, 1.38949549e-03,\n",
       "       2.02358965e-03, 2.94705170e-03, 4.29193426e-03, 6.25055193e-03,\n",
       "       9.10298178e-03, 1.32571137e-02, 1.93069773e-02, 2.81176870e-02,\n",
       "       4.09491506e-02, 5.96362332e-02, 8.68511374e-0...\n",
       "       3.72759372e+00, 5.42867544e+00, 7.90604321e+00, 1.15139540e+01,\n",
       "       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n",
       "       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n",
       "       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n",
       "       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n",
       "       6.86648845e+03, 1.00000000e+04]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_htuning.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e682a798-42c6-472a-b714-ba10ba720bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 719.6856730011514, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(lr_htuning.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f22d25-bb62-43ea-be09-a7e27db8c7fb",
   "metadata": {},
   "source": [
    "#### Logistic Regression Final Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5300f637-295f-4fe6-b686-57f9e5b61c2c",
   "metadata": {},
   "source": [
    "#### NOTE: In this case a high C value will prevent the model from conversion so we use the highest C value that converges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "beefed4f-23b0-4120-a050-4fee269058f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_lr_classifier = LogisticRegression(C=4,penalty='l2')\n",
    "tuned_lr_classifier.fit(train_data, train_labels)\n",
    "tuned_lr_predictions = tuned_lr_classifier.predict(test_data)\n",
    "accuracy_score(test_labels,tuned_lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa912b4c-196f-4b50-bab6-196fdfdcc36a",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a93a39fc-ab63-4fde-b79f-fefa47a8274e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=10)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(max_depth=10)\n",
    "rf_classifier.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ee47442b-fea7-4fc2-a34a-bc5f454bdc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8721804511278195"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predictions = rf_classifier.predict(test_data)\n",
    "accuracy_score(test_labels,rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d5513-8312-4ba0-81d5-0e79962c381f",
   "metadata": {},
   "source": [
    "## Random Forest Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "90ec4dc6-022b-4ff1-b4c9-ef65e97378e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = { 'n_estimators': [50,100,150],\n",
    "                 'max_depth': [None,10,20],\n",
    "                 'min_samples_split': [2,5,10],\n",
    "                 'max_features': ['sqrt','log2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "41f16079-3093-461d-9b5d-dc0e8c46410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_htuning = GridSearchCV(RandomForestClassifier(), rf_param_grid, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b5a59873-2cdb-4eca-ac0d-f022deb01dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.812 total time=   0.1s\n",
      "[CV 2/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.834 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.874 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.862 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.831 total time=   0.2s\n",
      "[CV 2/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.859 total time=   0.2s\n",
      "[CV 3/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.865 total time=   0.2s\n",
      "[CV 4/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.871 total time=   0.2s\n",
      "[CV 5/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.890 total time=   0.2s\n",
      "[CV 1/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.865 total time=   0.3s\n",
      "[CV 3/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.858 total time=   0.3s\n",
      "[CV 4/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.909 total time=   0.3s\n",
      "[CV 5/5] END max_depth=None, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.890 total time=   0.3s\n",
      "[CV 1/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.828 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.868 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.850 total time=   0.2s\n",
      "[CV 2/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.875 total time=   0.2s\n",
      "[CV 3/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.840 total time=   0.2s\n",
      "[CV 4/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.887 total time=   0.2s\n",
      "[CV 5/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.887 total time=   0.2s\n",
      "[CV 1/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.837 total time=   0.3s\n",
      "[CV 2/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.871 total time=   0.3s\n",
      "[CV 3/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.855 total time=   0.3s\n",
      "[CV 4/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END max_depth=None, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.890 total time=   0.3s\n",
      "[CV 1/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.853 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.871 total time=   0.1s\n",
      "[CV 3/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.849 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.877 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.831 total time=   0.1s\n",
      "[CV 2/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.853 total time=   0.2s\n",
      "[CV 3/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.846 total time=   0.2s\n",
      "[CV 4/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.871 total time=   0.2s\n",
      "[CV 5/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.862 total time=   0.2s\n",
      "[CV 1/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.824 total time=   0.3s\n",
      "[CV 2/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.856 total time=   0.3s\n",
      "[CV 3/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.840 total time=   0.3s\n",
      "[CV 4/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.881 total time=   0.3s\n",
      "[CV 5/5] END max_depth=None, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.881 total time=   0.3s\n",
      "[CV 1/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.803 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.843 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.865 total time=   0.1s\n",
      "[CV 1/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.821 total time=   0.2s\n",
      "[CV 2/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.856 total time=   0.2s\n",
      "[CV 3/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.868 total time=   0.2s\n",
      "[CV 4/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.893 total time=   0.2s\n",
      "[CV 5/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.903 total time=   0.2s\n",
      "[CV 1/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.828 total time=   0.3s\n",
      "[CV 2/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.868 total time=   0.3s\n",
      "[CV 3/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.858 total time=   0.4s\n",
      "[CV 4/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.887 total time=   0.4s\n",
      "[CV 5/5] END max_depth=None, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.868 total time=   0.4s\n",
      "[CV 1/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.815 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.853 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.855 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.846 total time=   0.2s\n",
      "[CV 2/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.865 total time=   0.2s\n",
      "[CV 3/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.843 total time=   0.2s\n",
      "[CV 4/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.877 total time=   0.2s\n",
      "[CV 5/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.865 total time=   0.2s\n",
      "[CV 1/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.862 total time=   0.3s\n",
      "[CV 3/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.865 total time=   0.3s\n",
      "[CV 4/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.909 total time=   0.3s\n",
      "[CV 5/5] END max_depth=None, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.881 total time=   0.3s\n",
      "[CV 1/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.831 total time=   0.0s\n",
      "[CV 2/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.877 total time=   0.0s\n",
      "[CV 1/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.840 total time=   0.1s\n",
      "[CV 2/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.850 total time=   0.2s\n",
      "[CV 3/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.840 total time=   0.2s\n",
      "[CV 4/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.890 total time=   0.2s\n",
      "[CV 5/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.884 total time=   0.2s\n",
      "[CV 1/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.828 total time=   0.3s\n",
      "[CV 2/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.859 total time=   0.3s\n",
      "[CV 3/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.852 total time=   0.3s\n",
      "[CV 4/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.893 total time=   0.3s\n",
      "[CV 5/5] END max_depth=None, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.868 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.828 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.846 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.827 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.871 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.834 total time=   0.2s\n",
      "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.856 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.849 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.899 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.856 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.850 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.862 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.890 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.874 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.843 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.856 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.849 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.831 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.871 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.865 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.896 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.865 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.862 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.849 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.896 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.881 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.843 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.877 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.877 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.834 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.856 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.862 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.868 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.871 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.824 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.862 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.865 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.899 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.887 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.821 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.862 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.890 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.862 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.850 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.856 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.849 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.887 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.884 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.834 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.859 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.868 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.890 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.881 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.828 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.856 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.827 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.874 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.846 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.868 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.862 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.877 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.877 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.834 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.862 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.865 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.884 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.868 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.824 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.837 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.827 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.865 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.831 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.871 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.836 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.877 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.871 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.837 total time=   0.2s\n",
      "[CV 2/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.871 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.862 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.874 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.877 total time=   0.2s\n",
      "[CV 1/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.859 total time=   0.0s\n",
      "[CV 2/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.865 total time=   0.0s\n",
      "[CV 3/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.858 total time=   0.0s\n",
      "[CV 5/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=50;, score=0.849 total time=   0.0s\n",
      "[CV 1/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.834 total time=   0.2s\n",
      "[CV 2/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.881 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.858 total time=   0.2s\n",
      "[CV 4/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.881 total time=   0.2s\n",
      "[CV 5/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=100;, score=0.877 total time=   0.2s\n",
      "[CV 1/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.834 total time=   0.3s\n",
      "[CV 2/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.865 total time=   0.3s\n",
      "[CV 3/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.865 total time=   0.3s\n",
      "[CV 4/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.906 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, max_features=sqrt, min_samples_split=2, n_estimators=150;, score=0.858 total time=   0.3s\n",
      "[CV 1/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.850 total time=   0.0s\n",
      "[CV 2/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.878 total time=   0.0s\n",
      "[CV 3/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.890 total time=   0.0s\n",
      "[CV 5/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=50;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.853 total time=   0.2s\n",
      "[CV 2/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.865 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.852 total time=   0.2s\n",
      "[CV 4/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.862 total time=   0.2s\n",
      "[CV 5/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=100;, score=0.881 total time=   0.2s\n",
      "[CV 1/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.862 total time=   0.3s\n",
      "[CV 3/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.858 total time=   0.3s\n",
      "[CV 4/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.881 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, max_features=sqrt, min_samples_split=5, n_estimators=150;, score=0.874 total time=   0.3s\n",
      "[CV 1/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.859 total time=   0.0s\n",
      "[CV 2/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.853 total time=   0.0s\n",
      "[CV 3/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.843 total time=   0.0s\n",
      "[CV 4/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.868 total time=   0.0s\n",
      "[CV 5/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=50;, score=0.865 total time=   0.0s\n",
      "[CV 1/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.850 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.871 total time=   0.2s\n",
      "[CV 4/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.893 total time=   0.2s\n",
      "[CV 5/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=100;, score=0.887 total time=   0.2s\n",
      "[CV 1/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.850 total time=   0.3s\n",
      "[CV 2/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.853 total time=   0.3s\n",
      "[CV 3/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.858 total time=   0.3s\n",
      "[CV 4/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.871 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, max_features=sqrt, min_samples_split=10, n_estimators=150;, score=0.877 total time=   0.3s\n",
      "[CV 1/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.793 total time=   0.0s\n",
      "[CV 2/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.849 total time=   0.0s\n",
      "[CV 4/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=50;, score=0.871 total time=   0.0s\n",
      "[CV 1/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.834 total time=   0.2s\n",
      "[CV 2/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.865 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.871 total time=   0.2s\n",
      "[CV 4/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.884 total time=   0.2s\n",
      "[CV 5/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=100;, score=0.893 total time=   0.2s\n",
      "[CV 1/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.846 total time=   0.3s\n",
      "[CV 2/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.853 total time=   0.3s\n",
      "[CV 3/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.858 total time=   0.3s\n",
      "[CV 4/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.899 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, max_features=log2, min_samples_split=2, n_estimators=150;, score=0.887 total time=   0.3s\n",
      "[CV 1/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.865 total time=   0.0s\n",
      "[CV 3/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.846 total time=   0.0s\n",
      "[CV 4/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.840 total time=   0.0s\n",
      "[CV 5/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=50;, score=0.852 total time=   0.0s\n",
      "[CV 1/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.840 total time=   0.2s\n",
      "[CV 2/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.868 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.852 total time=   0.2s\n",
      "[CV 4/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.887 total time=   0.2s\n",
      "[CV 5/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=100;, score=0.858 total time=   0.2s\n",
      "[CV 1/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.840 total time=   0.3s\n",
      "[CV 2/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.871 total time=   0.3s\n",
      "[CV 3/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.855 total time=   0.3s\n",
      "[CV 4/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.893 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, max_features=log2, min_samples_split=5, n_estimators=150;, score=0.871 total time=   0.3s\n",
      "[CV 1/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.828 total time=   0.0s\n",
      "[CV 2/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.865 total time=   0.0s\n",
      "[CV 3/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.862 total time=   0.0s\n",
      "[CV 4/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=50;, score=0.852 total time=   0.0s\n",
      "[CV 1/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.824 total time=   0.2s\n",
      "[CV 2/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.846 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.868 total time=   0.1s\n",
      "[CV 4/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.881 total time=   0.1s\n",
      "[CV 5/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=100;, score=0.884 total time=   0.2s\n",
      "[CV 1/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.846 total time=   0.3s\n",
      "[CV 2/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.865 total time=   0.3s\n",
      "[CV 3/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.849 total time=   0.3s\n",
      "[CV 4/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.893 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, max_features=log2, min_samples_split=10, n_estimators=150;, score=0.871 total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [None, 10, 20],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_htuning.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9800a494-9178-42e1-8f1b-1c6d081967f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "print(rf_htuning.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9cd2f9-3366-4cf1-80fe-175fbcf040cf",
   "metadata": {},
   "source": [
    "#### Random Forest Final Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bb6ca92b-fd85-4f5f-b18d-f444317292ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8847117794486216"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_rf_classifier = RandomForestClassifier(max_depth=None, max_features='sqrt', min_samples_split=2, n_estimators=150)\n",
    "tuned_rf_classifier.fit(train_data, train_labels)\n",
    "tuned_rf_predictions = tuned_rf_classifier.predict(test_data)\n",
    "accuracy_score(test_labels,tuned_rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b2809-8067-4e4d-a157-bd0e3dbf649e",
   "metadata": {},
   "source": [
    "# **3. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b9547-6497-4acd-a858-fb7769409893",
   "metadata": {},
   "source": [
    "## Best Performing Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "35b5239e-dbb7-4488-bd42-fcc5a48d1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dict = {\"SVM\":round(accuracy_score(test_labels,tuned_svm_predictions),3),\n",
    "                   \"Naive Bayes\":round(accuracy_score(test_labels,tuned_gnb_predictions),3),\n",
    "                   \"Logistic Regression\":round(accuracy_score(test_labels,tuned_lr_predictions),3),\n",
    "                   \"Random Forest\":round(accuracy_score(test_labels,tuned_rf_predictions),3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a10a136e-6803-4629-86fd-ca65b30c33cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM : 0.942\n",
      "Naive Bayes : 0.83\n",
      "Logistic Regression : 0.952\n",
      "Random Forest : 0.885\n"
     ]
    }
   ],
   "source": [
    "for key in evaluation_dict:\n",
    "    print(key,\":\",evaluation_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c6ce61-39f9-45d0-9a43-80fa4eb489c5",
   "metadata": {},
   "source": [
    "### As was observed in the exploration section when getting the difference between the means, the RAM is the feature that contributes most to the price range, followed by battery power and px width and height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2505bc57-b8cf-48b0-9204-354df8dd6eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1850x1050 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = tuned_rf_classifier.feature_importances_\n",
    "\n",
    "forest_importances = pd.Series(importance, index=train_data.columns)\n",
    "std = np.std([tree.feature_importances_ for tree in tuned_rf_classifier.estimators_], axis=0)\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.set_size_inches(18.5, 10.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f961905-215c-48e2-9463-be70a39a420d",
   "metadata": {},
   "source": [
    "# **4. Predicting the price_range of the given test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cc049bbc-c88c-4fc0-bdd8-9e99795df18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices_test_df = pd.read_excel(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d3721721-1b98-4607-895a-ad89ff04bc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>...</th>\n",
       "      <th>pc</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1043</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>226</td>\n",
       "      <td>1412</td>\n",
       "      <td>3476</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0.8</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>746</td>\n",
       "      <td>857</td>\n",
       "      <td>3895</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1807</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1270</td>\n",
       "      <td>1366</td>\n",
       "      <td>2396</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1546</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>295</td>\n",
       "      <td>1752</td>\n",
       "      <td>3893</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1434</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>749</td>\n",
       "      <td>810</td>\n",
       "      <td>1773</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0   1           1043     1          1.8         1  14       0           5   \n",
       "1   2            841     1          0.5         1   4       1          61   \n",
       "2   3           1807     1          2.8         0   1       0          27   \n",
       "3   4           1546     0          0.5         1  18       1          25   \n",
       "4   5           1434     0          1.4         0  11       1          49   \n",
       "\n",
       "   m_dep  mobile_wt  ...  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0    0.1        193  ...  16        226      1412  3476    12     7   \n",
       "1    0.8        191  ...  12        746       857  3895     6     0   \n",
       "2    0.9        186  ...   4       1270      1366  2396    17    10   \n",
       "3    0.5         96  ...  20        295      1752  3893    10     0   \n",
       "4    0.5        108  ...  18        749       810  1773    15     8   \n",
       "\n",
       "   talk_time  three_g  touch_screen  wifi  \n",
       "0          2        0             1     0  \n",
       "1          7        1             0     0  \n",
       "2         10        0             1     1  \n",
       "3          7        1             1     0  \n",
       "4          7        1             0     1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e4e3a671-2801-4279-8b54-8df535864fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_test_devices_df = devices_test_df.drop('id', axis=1).apply(lambda x: x/x.max(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "187a9a6d-14f3-4bcb-a523-e03fb3e93d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_devices_predictions = tuned_lr_classifier.predict(normalized_test_devices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "414fb597-059c-4de6-8ca4-02b7b96795c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices_test_df['price_range'] = test_devices_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7b913dd2-42e8-4c52-98ce-074d0a0acbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1043</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>1412</td>\n",
       "      <td>3476</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0.8</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>746</td>\n",
       "      <td>857</td>\n",
       "      <td>3895</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1807</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>...</td>\n",
       "      <td>1270</td>\n",
       "      <td>1366</td>\n",
       "      <td>2396</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1546</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>295</td>\n",
       "      <td>1752</td>\n",
       "      <td>3893</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1434</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.5</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>749</td>\n",
       "      <td>810</td>\n",
       "      <td>1773</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>1700</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0.5</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>644</td>\n",
       "      <td>913</td>\n",
       "      <td>2121</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>609</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.9</td>\n",
       "      <td>186</td>\n",
       "      <td>...</td>\n",
       "      <td>1152</td>\n",
       "      <td>1632</td>\n",
       "      <td>1933</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>477</td>\n",
       "      <td>825</td>\n",
       "      <td>1223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>1533</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>832</td>\n",
       "      <td>2509</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>457</td>\n",
       "      <td>608</td>\n",
       "      <td>2828</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0       1           1043     1          1.8         1  14       0           5   \n",
       "1       2            841     1          0.5         1   4       1          61   \n",
       "2       3           1807     1          2.8         0   1       0          27   \n",
       "3       4           1546     0          0.5         1  18       1          25   \n",
       "4       5           1434     0          1.4         0  11       1          49   \n",
       "..    ...            ...   ...          ...       ...  ..     ...         ...   \n",
       "995   996           1700     1          1.9         0   0       1          54   \n",
       "996   997            609     0          1.8         1   0       0          13   \n",
       "997   998           1185     0          1.4         0   1       1           8   \n",
       "998   999           1533     1          0.5         1   0       0          50   \n",
       "999  1000           1270     1          0.5         0   4       1          35   \n",
       "\n",
       "     m_dep  mobile_wt  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0      0.1        193  ...        226      1412  3476    12     7          2   \n",
       "1      0.8        191  ...        746       857  3895     6     0          7   \n",
       "2      0.9        186  ...       1270      1366  2396    17    10         10   \n",
       "3      0.5         96  ...        295      1752  3893    10     0          7   \n",
       "4      0.5        108  ...        749       810  1773    15     8          7   \n",
       "..     ...        ...  ...        ...       ...   ...   ...   ...        ...   \n",
       "995    0.5        170  ...        644       913  2121    14     8         15   \n",
       "996    0.9        186  ...       1152      1632  1933     8     1         19   \n",
       "997    0.5         80  ...        477       825  1223     5     0         14   \n",
       "998    0.4        171  ...         38       832  2509    15    11          6   \n",
       "999    0.1        140  ...        457       608  2828     9     2          3   \n",
       "\n",
       "     three_g  touch_screen  wifi  price_range  \n",
       "0          0             1     0            3  \n",
       "1          1             0     0            3  \n",
       "2          0             1     1            2  \n",
       "3          1             1     0            3  \n",
       "4          1             0     1            1  \n",
       "..       ...           ...   ...          ...  \n",
       "995        1             1     0            2  \n",
       "996        0             1     1            1  \n",
       "997        1             0     0            0  \n",
       "998        0             1     0            2  \n",
       "999        1             0     1            2  \n",
       "\n",
       "[1000 rows x 22 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6bb69cc8-4aa2-4153-9371-bcd71a7950da",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices_test_df.to_excel('test_predicted.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea82df5-8d4e-4ade-ba16-070780ee0c9d",
   "metadata": {},
   "source": [
    "# **5. Exporting the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a54c1e52-6d4b-4518-ab52-557f8b20f261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price_prediction_model.pkl']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tuned_lr_classifier, 'price_prediction_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470bd794-90e2-480d-9765-be3b1172766b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
